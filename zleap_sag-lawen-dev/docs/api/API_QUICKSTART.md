# DataFlow API å¿«é€Ÿå¼€å§‹

**5 åˆ†é’Ÿå¿«é€Ÿå¯åŠ¨ DataFlow API æœåŠ¡**

---

## ğŸš€ å¿«é€Ÿå¯åŠ¨ï¼ˆ3 æ­¥ï¼‰

### æ­¥éª¤ 1ï¼šå®‰è£…ä¾èµ–

```bash
# å…‹éš†é¡¹ç›®ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
git clone https://github.com/zleap-team/dataflow.git
cd dataflow

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# å®‰è£…ä¾èµ–ï¼ˆä½¿ç”¨ uv æ›´å¿«ï¼‰
uv pip install -e "."

# æˆ–ä½¿ç”¨ pip
pip install -e "."
```

### æ­¥éª¤ 2ï¼šé…ç½®ç¯å¢ƒ

```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè‡³å°‘é…ç½®ï¼š
# - LLM_API_KEY: ä½ çš„ OpenAI API Key
# - MYSQL_PASSWORD: æ•°æ®åº“å¯†ç 
```

**æœ€å°é…ç½®**ï¼ˆä½¿ç”¨æœ¬åœ°æ•°æ®åº“ï¼‰ï¼š
```bash
# .env
LLM_API_KEY=sk-your-openai-api-key
MYSQL_PASSWORD=your_mysql_password
```

### æ­¥éª¤ 3ï¼šå¯åŠ¨æœåŠ¡

```bash
# æ–¹å¼ 1ï¼šå¼€å‘æ¨¡å¼ï¼ˆæ¨èï¼Œè‡ªåŠ¨é‡è½½ï¼‰
python -m dataflow.api.main

# æ–¹å¼ 2ï¼šç”Ÿäº§æ¨¡å¼
python scripts/start_api.py

# æ–¹å¼ 3ï¼šä½¿ç”¨ uvicorn
uvicorn dataflow.api.main:app --reload
```

**å¯åŠ¨æˆåŠŸå**ï¼Œè®¿é—®ï¼š
- ğŸ“š API æ–‡æ¡£: http://localhost:8000/api/docs
- ğŸ“– ReDoc: http://localhost:8000/api/redoc
- âœ… å¥åº·æ£€æŸ¥: http://localhost:8000/health

---

## ğŸ¯ å¿«é€Ÿæµ‹è¯•

### 1. åˆ›å»ºä¿¡æ¯æº

```bash
curl -X POST http://localhost:8000/api/v1/sources \
  -H "Content-Type: application/json" \
  -d '{
    "name": "æµ‹è¯•çŸ¥è¯†åº“",
    "description": "æˆ‘çš„ç¬¬ä¸€ä¸ªæ•°æ®æº"
  }'
```

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
  "success": true,
  "data": {
    "id": "550e8400-e29b-41d4-a716-446655440000",
    "name": "æµ‹è¯•çŸ¥è¯†åº“",
    "description": "æˆ‘çš„ç¬¬ä¸€ä¸ªæ•°æ®æº",
    "created_time": "2024-01-01T00:00:00"
  },
  "message": "ä¿¡æ¯æºåˆ›å»ºæˆåŠŸ"
}
```

ğŸ’¡ **è®°ä½è¿™ä¸ª `id`ï¼Œåç»­æ­¥éª¤éœ€è¦ç”¨åˆ°ï¼**

### 2. æŸ¥çœ‹é»˜è®¤å®ä½“ç±»å‹

```bash
curl http://localhost:8000/api/v1/entity-types/defaults
```

è¿”å› 6 ç§é»˜è®¤å®ä½“ç»´åº¦ï¼š
- â° **time** - æ—¶é—´
- ğŸ“ **location** - åœ°ç‚¹
- ğŸ‘¤ **person** - äººå‘˜
- ğŸ’¡ **topic** - è¯é¢˜
- ğŸ¯ **action** - è¡Œä¸º
- ğŸ·ï¸ **tags** - æ ‡ç­¾

### 3. åˆ›å»ºè‡ªå®šä¹‰å®ä½“ç±»å‹

```bash
curl -X POST "http://localhost:8000/api/v1/sources/{source_config_id}/entity-types" \
  -H "Content-Type: application/json" \
  -d '{
    "type": "priority",
    "name": "ä¼˜å…ˆçº§",
    "description": "ä»»åŠ¡çš„ä¼˜å…ˆçº§ï¼ˆé«˜ã€ä¸­ã€ä½ï¼‰",
    "weight": 1.3
  }'
```

### 4. ä¸Šä¼ æ–‡æ¡£

```bash
# åˆ›å»ºæµ‹è¯•æ–‡æ¡£
cat > test_doc.md << EOF
# AI æŠ€æœ¯ç®€ä»‹

## æœºå™¨å­¦ä¹ 
æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯ã€‚

## æ·±åº¦å­¦ä¹ 
æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚
EOF

# ä¸Šä¼ æ–‡æ¡£
curl -X POST "http://localhost:8000/api/v1/sources/{source_config_id}/documents/upload" \
  -F "file=@test_doc.md" \
  -F "auto_process=true"
```

### 5. æ‰§è¡Œæœç´¢

```bash
curl -X POST "http://localhost:8000/api/v1/pipeline/search" \
  -H "Content-Type: application/json" \
  -d '{
    "source_config_id": "{source_config_id}",
    "query": "æœºå™¨å­¦ä¹ ",
    "mode": "llm",
    "top_k": 5
  }'
```

---

## ğŸ³ ä½¿ç”¨ Dockerï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰

### Docker Compose ä¸€é”®å¯åŠ¨

```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘ .env é…ç½®

# å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼ˆAPI + MySQL + ES + Redisï¼‰
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f api

# åˆå§‹åŒ–æ•°æ®åº“
docker-compose exec api python scripts/init_database.py
docker-compose exec api python scripts/init_es_indices.py
```

è®¿é—®ï¼šhttp://localhost:8000/api/docs

---

## ğŸ“š API åŠŸèƒ½é€Ÿè§ˆ

### æ ¸å¿ƒæ¥å£

| æ¨¡å— | æ¥å£ | åŠŸèƒ½ |
|------|------|------|
| **ä¿¡æ¯æº** | `POST /api/v1/sources` | åˆ›å»ºä¿¡æ¯æº |
| **å®ä½“ç»´åº¦** | `POST /api/v1/sources/{id}/entity-types` | è‡ªå®šä¹‰å®ä½“ç±»å‹ |
| **æ–‡æ¡£** | `POST /api/v1/sources/{id}/documents/upload` | ä¸Šä¼ æ–‡æ¡£ |
| **æµç¨‹** | `POST /api/v1/pipeline/run` | å¼‚æ­¥æ‰§è¡Œå®Œæ•´æµç¨‹ |
| **ä»»åŠ¡** | `GET /api/v1/tasks/{id}` | æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€ |

### æµç¨‹ç»„åˆï¼ˆå¯åˆ†å¯åˆï¼‰

```bash
# æ–¹å¼ 1ï¼šå®Œæ•´æµç¨‹ï¼ˆLoad â†’ Extract â†’ Searchï¼‰
POST /api/v1/pipeline/run

# æ–¹å¼ 2ï¼šå•ç‹¬æ‰§è¡Œ
POST /api/v1/pipeline/load      # åª Load
POST /api/v1/pipeline/extract   # åª Extract
POST /api/v1/pipeline/search    # åª Search

# æ–¹å¼ 3ï¼šæ–‡æ¡£ä¸Šä¼ è‡ªåŠ¨å¤„ç†
POST /api/v1/sources/{id}/documents/upload?auto_process=true
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: å¯åŠ¨å¤±è´¥ - ç«¯å£è¢«å ç”¨

```bash
# æŸ¥çœ‹å ç”¨è¿›ç¨‹
lsof -i :8000

# æˆ–ä¿®æ”¹ç«¯å£
API_PORT=8001 python -m dataflow.api.main
```

### Q2: æ•°æ®åº“è¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥ MySQL æ˜¯å¦è¿è¡Œ
mysql -u root -p

# æ£€æŸ¥é…ç½®
cat .env | grep MYSQL
```

### Q3: LLM API è°ƒç”¨å¤±è´¥

```bash
# æ£€æŸ¥ API Key
echo $LLM_API_KEY

# æµ‹è¯•è¿æ¥
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $LLM_API_KEY"
```

### Q4: æ–‡æ¡£ä¸Šä¼ å¤±è´¥

```bash
# æ£€æŸ¥ä¸Šä¼ ç›®å½•æƒé™
mkdir -p ./uploads
chmod 755 ./uploads

# æ£€æŸ¥æ–‡ä»¶å¤§å°é™åˆ¶
# ä¿®æ”¹ .env: MAX_UPLOAD_SIZE=209715200  # 200MB
```

---

## ğŸ“– å®Œæ•´æ–‡æ¡£

- **API è¯¦ç»†æ–‡æ¡£**: [docs/api.md](./api.md)
- **é¡¹ç›® README**: [docs/README.md](./README.md)
- **æ¶æ„è®¾è®¡**: [docs/architecture.md](./architecture.md)
- **æ•°æ®åº“è®¾è®¡**: [docs/database.md](./database.md)

---

## ğŸ‰ ä¸‹ä¸€æ­¥

1. âœ… **æµè§ˆ API æ–‡æ¡£**: http://localhost:8000/api/docs
2. ğŸ“ **åˆ›å»ºç¬¬ä¸€ä¸ªä¿¡æ¯æº**
3. ğŸ“¤ **ä¸Šä¼ æ–‡æ¡£æµ‹è¯•**
4. ğŸ” **æ‰§è¡Œæœç´¢æŸ¥è¯¢**
5. ğŸš€ **é›†æˆåˆ°ä½ çš„ Web UI**

---

## ğŸ’¡ æç¤º

- å¼€å‘æ—¶ä½¿ç”¨ `DEBUG=true` æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
- ç”Ÿäº§ç¯å¢ƒé…ç½® `API_WORKERS=4` å¯ç”¨å¤šè¿›ç¨‹
- ä½¿ç”¨ Redis ç¼“å­˜æå‡æ€§èƒ½
- å®šæœŸå¤‡ä»½æ•°æ®åº“

---

## ğŸ†˜ éœ€è¦å¸®åŠ©ï¼Ÿ

- ğŸ“§ Email: contact@zleap.ai
- ğŸ’¬ GitHub Issues: https://github.com/zleap-team/dataflow/issues
- ğŸ“– å®Œæ•´æ–‡æ¡£: [docs/](./README.md)

---

**Made with â¤ï¸ by Zleap Team**

