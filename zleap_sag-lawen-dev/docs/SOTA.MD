# SAG Search Optimization Log (SOTA)

> State-of-the-Art tracking for SAG search optimization on HotpotQA benchmark.

---

## ğŸ“Š Current Performance

| Metric | Value | Date |
|--------|-------|------|
| **Overall Recall** | **93-94%** | 2025-12-12 |
| Perfect Recall (100%) | 44-47/50 | - |
| Partial Recall | 5-7/50 | - |
| Zero Recall (0%) | 0-1/50 | - |

> ğŸ‰ **v2.1 ä¼˜åŒ–å**: 50 ä¸ªé—®é¢˜æµ‹è¯•ï¼Œæ ‡å‡†é…ç½® `max_results=10`ï¼Œå¬å›ç‡ç¨³å®šåœ¨ 93-94%

---

## ğŸ”„ Optimization History

### v2.2 - Step4 æƒé‡æ–‡æ¡£ä¸å¯è§£é‡Šæ€§ (2025-12-13) ğŸ“

**æ›´æ–°å†…å®¹ï¼š**

1. å®Œæ•´è®°å½• Step4 çš„åŠ æƒ RRF å…¬å¼ä¸å‚æ•°ï¼ˆk_rrf=60ï¼Œw_sim=1.5ï¼Œw_rel=0.5ï¼Œw_den=0.2ï¼‰
2. è¡¥å……ä¸‰ç§å¾—åˆ†ç»„ä»¶çš„è®¡ç®—æ–¹å¼ï¼š
   - similarityï¼šæ²¿ç”¨ Step1 ä½™å¼¦ç›¸ä¼¼åº¦
   - relationï¼šæŒ‰ hop è¡°å‡å¹¶å¯¹ç›®æ ‡ç±»å‹åŠ æƒ 1.5
   - densityï¼šåŸºäºå‡ºç°æ¬¡æ•°ä½¿ç”¨ weight * ln(1+count) / step
3. æ˜ç¡® Step4 è®¡ç®—æµç¨‹ï¼ˆæ’åºå– rank â†’ åŠ æƒ RRF â†’ ä½œä¸º weight/score è¿”å›ï¼‰ï¼Œä¾¿äºæ’æŸ¥æ’åº/åŠ æƒé—®é¢˜

**ç›®çš„ï¼š** æå‡æƒé‡è®¡ç®—çš„å¯è§£é‡Šæ€§å’Œæ’é”™æ•ˆç‡ï¼Œä¸ºåç»­è°ƒå‚ä¸å®éªŒå¯¹æ¯”æä¾›æ¸…æ™°åŸºçº¿ã€‚

### v2.1 - æ’åºä¿®å¤ + å™ªéŸ³è¿‡æ»¤ (2025-12-12) ğŸ‰

**é—®é¢˜å‘ç°ï¼š**

1. **Step5 æ’åº Bug**: PageRank åæŒ‰ `pagerank_score` æ’åºï¼Œä½†æ··åˆæƒé‡ååº”æŒ‰ `weight` æ’åº
2. **åˆ†è¯åŒ¹é…å™ªéŸ³**: åˆ†è¯å™¨ä½¿ç”¨å‰ç¼€åŒ¹é… `LIKE 'New%'`ï¼Œå¯¼è‡´ "New" åŒ¹é…åˆ° 28 ä¸ªæ— å…³å®ä½“
3. **è¯„ä¼°åŒ¹é…é—æ¼**: å¤åˆæ ‡é¢˜å¦‚ `# A | # B` æ— æ³•åŒ¹é… oracle æ ‡é¢˜ `A`

**ä¿®å¤æªæ–½ï¼š**

1. **æ’åºä¿®å¤**:
   ```python
   # ä¿®å¤å‰ï¼šæŒ‰ pagerank_score æ’åº
   sorted_contents = sorted(contents, key=lambda x: x["pagerank_score"], reverse=True)
   
   # ä¿®å¤åï¼šæŒ‰æ··åˆæƒé‡æ’åº
   content["weight"] = 0.9 * original_weight + 0.1 * scaled_pagerank
   sorted_contents = sorted(contents, key=lambda x: x["weight"], reverse=True)
   ```

2. **åˆ†è¯å™ªéŸ³è¿‡æ»¤**:
   ```python
   # åˆ†è¯å™¨è¡¥å……å¬å›ç¦ç”¨å‰ç¼€åŒ¹é…ï¼Œåªç”¨ç²¾ç¡®åŒ¹é…
   matched_entities = await self._mysql_exact_search_entities(
       ...,
       use_prefix_match=False  # é¿å… "New" åŒ¹é…åˆ° "New York" ç­‰å™ªéŸ³
   )
   ```

3. **è¯„ä¼°åŒ¹é…å¢å¼º**:
   ```python
   # æ–°å¢æ ‡é¢˜åŒ…å«åŒ¹é…ç­–ç•¥
   for oracle_title, chunk in oracle_by_title.items():
       if oracle_title in normalized_title:
           matched_chunk = chunk
           break
   ```

4. **å‚æ•°è°ƒæ•´**:
   - PageRank æ··åˆæ¯”ä¾‹: 90% åŸå§‹æƒé‡ + 10% PageRank
   - æ ‡å‡†é…ç½®ä¿æŒ `max_results=10`

**æ•ˆæœï¼š**
- å¬å›ç‡: 72% â†’ **93-94%** (æ ‡å‡†é…ç½® `max_results=10`)
- å¬å›ç‡: 72% â†’ **98-100%** (å®½æ¾é…ç½® `max_results=25`)
- Zero recall: 7 â†’ **0-1**
- 50 ä¸ªé—®é¢˜æµ‹è¯•ç¨³å®š

**å‰©ä½™ Partial Recall åˆ†æï¼š**
- æ¯”è¾ƒé—®é¢˜ (A vs B): ç¬¬äºŒä¸ªå¯¹è±¡æœ‰æ—¶æ’åœ¨ 11-20 ä½
- å¤šè·³é—®é¢˜: éœ€è¦ 3+ è·³å…³è”çš„æ®µè½æ’åé å

---

### v2.0 - æœç´¢æç¤ºè¯é‡æ„ (2025-12-12) ğŸ‰

**æ ¸å¿ƒæ”¹è¿›ï¼š**

1. **æç¤ºè¯è®¾è®¡åŸåˆ™**ï¼š
   - ç›®çš„å¯¼å‘ï¼šè¯´æ˜ç¼˜ç”±ï¼Œè®© LLM ç†è§£ä¸ºä»€ä¹ˆè¿™æ ·åš
   - çµæ´»ä¸æ­»æ¿ï¼šä¸é™å®šå…·ä½“æ•°å­—ï¼Œè®© LLM è‡ªå·±åˆ¤æ–­
   - æ ¸å¿ƒåŸåˆ™ï¼š**å®å¤šå‹¿å°‘ï¼Œæ— æ³•ç¡®å®šæ’é™¤çš„å°±åŠ å…¥**

2. **å››ä¸ªè¾“å‡ºæ˜ç¡®åˆ†å·¥**ï¼š
   - `rewritten_query`: é‡å†™é—®é¢˜ï¼Œä½¿æ„å›¾æ¸…æ™°
   - `entities`: æœç´¢å…³é”®è¯ï¼ˆä¸é—æ¼ä»»ä½•ä¸“æœ‰åè¯ï¼‰
   - `focus_entity_types`: çº¿ç´¢ç»´åº¦ï¼ˆæœç´¢è·¯å¾„ï¼Œè¦†ç›–é¢å¹¿ï¼‰
   - `target_entity_types`: ç›®æ ‡ç»´åº¦ï¼ˆç­”æ¡ˆä½ç½®ï¼Œç”¨äºæ’åºåŠ æƒï¼‰

3. **å…³é”®å¼ºè°ƒ**ï¼š
   - æ¯”è¾ƒé—®é¢˜å¿…é¡»æå–æ‰€æœ‰æ¯”è¾ƒå¯¹è±¡
   - æŒ‡ä»£é—®é¢˜è¦ä»å€™é€‰ä¸­æ‰¾å‡ºå®é™…åç§°
   - æ¯ä¸ªå…³é”®è¯ = ä¸€ä¸ªæœç´¢å…¥å£ï¼Œæ¼æ‰å°±ä¸¢å¤±æ–‡æ¡£

**æ•ˆæœï¼š**
- 8/8 æ¬¡æµ‹è¯•ï¼š**100% å¬å›ç‡**
- ç¨³å®šæ€§å¤§å¹…æå‡

---

### v1.9 - å¤šè·³ä¼ é€’å…³è” + ç›®æ ‡ç»´åº¦åŠ æƒ (2025-12-12) ğŸ¯

**æ ¸å¿ƒæ”¹åŠ¨ï¼š**

1. **LLM Query åˆ†ææ‰©å±•**:
   - æ–°å¢ `target_entity_types` å­—æ®µï¼ˆç›®æ ‡ç»´åº¦ï¼‰
   - `focus_entity_types` ç”¨äº Recall/Expand è¿‡æ»¤ï¼ˆçº¿ç´¢ç»´åº¦ï¼‰
   - `target_entity_types` ç”¨äº Rerank åŠ æƒï¼ˆç­”æ¡ˆç»´åº¦ï¼‰

2. **Rerank æƒé‡å…¬å¼ä¼˜åŒ–**:
   ```python
   # æ—§å…¬å¼
   weight = 0.5 * similarity_score + log(1 + key_weight_sum)
   
   # æ–°å…¬å¼ï¼šå¤šè·³è¡°å‡ + ç›®æ ‡ç»´åº¦åŠ æƒ
   hop_factor = 1.0 / (1.0 + hop)  # hop=0â†’1.0, hop=1â†’0.5
   target_boost = 1.5 if entity_type in target_types else 1.0
   relation_contribution = hop_factor * target_boost * weight
   
   final_score = similarity_score + bonus  # åŠ åˆ†æ¨¡å¼ï¼Œä¿åº• similarity
   ```

3. **è¿‡æ»¤é€»è¾‘è°ƒæ•´**:
   - Step1 é¢„è¿‡æ»¤é˜ˆå€¼é™ä½åˆ° 0.1ï¼ˆä¿ç•™æ›´å¤šå€™é€‰ï¼‰
   - Step4 ä¹‹ååŸºäºæ–°æƒé‡è¿›è¡Œæœ€ç»ˆè¿‡æ»¤ï¼ˆé˜ˆå€¼ 0.45ï¼‰

**Partial Recall æ¡ˆä¾‹ä¿®å¤æ•ˆæœï¼š**

| æ¡ˆä¾‹ | åŸå§‹åˆ†æ•° | æ–°åˆ†æ•° | çŠ¶æ€ |
|------|----------|--------|------|
| Adriana Trigiani | 0.298 | **1.098** | âœ… å¬å› |
| Shirley Temple | 0.393 | **1.193** | âœ… å¬å› |
| Management consulting | 0.430 | **0.541** | âœ… å¬å› |

**é—®é¢˜ï¼šLLM ä¸ç¡®å®šæ€§**
- 3 æ¬¡æµ‹è¯•å¬å›ç‡æ³¢åŠ¨ï¼š75% â†’ 65% â†’ 65%
- Perfect Recall æ³¢åŠ¨ï¼š6 â†’ 6 â†’ 5
- Zero Recall æ³¢åŠ¨ï¼š1 â†’ 3 â†’ 2

**ä¿®æ”¹æ–‡ä»¶ï¼š**
- `dataflow/modules/search/config.py`: æ·»åŠ  `target_entity_types` å­—æ®µ
- `dataflow/modules/search/recall.py`: Schema å’Œè§£æé€»è¾‘
- `dataflow/modules/search/ranking/pagerank_section.py`: æ–°æƒé‡å…¬å¼
- `prompts/search.yaml`: æç¤ºè¯æ›´æ–°

---

### v1.3 - Stability Test (2025-12-12) ğŸ“Š

**Test Run:** `--batch-size 20 --concurrency 20 --track-zero-recall`

| Metric | v1.1 Result | v1.3 Result | Variance |
|--------|-------------|-------------|----------|
| Overall Recall | 85% | 81% | **-4%** |
| Perfect Recall | 36 | 34 | -2 |
| Partial Recall | 13 | 13 | 0 |
| Zero Recall | 1 | 3 | +2 |

**Analysis:** LLM éšæœºæ€§å¯¼è‡´ç»“æœæ³¢åŠ¨æ˜æ˜¾ï¼Œéœ€è¦å¤šæ¬¡æµ‹è¯•å–å¹³å‡å€¼

**New Zero Recall Cases:**
1. `Big Stone Gap` - **retrieved: 0** (å®Œå…¨æœªæ£€ç´¢åˆ°ä»»ä½•æ–‡æ¡£)
2. `Badly Drawn Boy or Wolf Alice` - retrieved: 3 (æ£€ç´¢åˆ°é”™è¯¯æ–‡æ¡£)
3. `VCU Rams basketball` - retrieved: 10 (æ£€ç´¢åˆ°é”™è¯¯æ–‡æ¡£)

---

### v1.2 - Stage Name Fix (2025-12-12) ğŸ”§

**Issue Found (from partial recall analysis):**
```
Question: "Which performance act has higher ratio, Badly Drawn Boy or Wolf Alice?"
Problem: 
  - Correct doc "# Badly Drawn Boy" has person: "Badly Drawn Boy"
  - Wrong doc "# Badly Drawn Boy discography" has tags: "Badly Drawn Boy"
  - Search returned wrong doc because tags classification was incorrect
```

**Changes:**
- Update person type: explicitly include stage names, pen names, pseudonyms
- Add examples: "Badly Drawn Boy", "Wolf Alice", "Mark Twain"
- Expand common mistakes section

**Status:** âŒ æœªç”Ÿæ•ˆ - é—®é¢˜ä»å‡ºç°åœ¨ zero recall ä¸­

---

### v1.1 - Entity Type Enhancement (2025-12-12) âœ…

**Changes:**
- æ–°å¢ `nationality` ç±»å‹ï¼ˆå›½ç±ï¼šAmerican, British...ï¼‰
- æ–°å¢ `profession` ç±»å‹ï¼ˆèŒä¸šï¼šdirector, writer...ï¼‰
- é™ä½ `tags` æƒé‡ï¼ˆ0.5â†’0.3ï¼‰å¹¶æ ‡è®°ä¸º "LastResort"
- ä¼˜åŒ– person/organization/work ç±»å‹æè¿°
- å¢å¼ºæå–æç¤ºè¯ï¼šæ˜ç¡®åˆ†ç±»è§„åˆ™ï¼Œé¿å…è¯¯å…¥ tags
- å¢å¼ºæœç´¢æç¤ºè¯ï¼šæ¯”è¾ƒé—®é¢˜å¿…é¡»æå–æ‰€æœ‰æ¯”è¾ƒå¯¹è±¡

**Result:** 
| Metric | Before | After | Change |
|--------|--------|-------|--------|
| Overall Recall | 82% | **85%** | **+3%** |
| Perfect Recall | 33 | 36 | +3 |
| Partial Recall | 16 | 13 | -3 |
| Zero Recall | 1 | 1 | 0 |

**Analysis:** å®ä½“åˆ†ç±»ä¼˜åŒ–æœ‰æ•ˆï¼Œå‡å°‘äº† tags æ¡¶çš„è¯¯åˆ†ç±»

---

### v1.0 - Baseline + Focus Entity Types (2025-12-11)

**Key Features:**
- ä¸‰é˜¶æ®µæœç´¢æ¶æ„: Recall â†’ Expand â†’ Rerank
- LLM æ™ºèƒ½è¯†åˆ« focus_entity_typesï¼ˆç™½åå•ï¼‰
- PageRank é‡æ’åºç®—æ³•

**Recall Rate:** 78-82% (fluctuates due to LLM non-determinism)

---

## ğŸ” Bad Case Analysis

### ğŸš¨ Critical Issue: ES ç´¢å¼•ä¸¥é‡ä¸å®Œæ•´ (v1.4)

**è¯Šæ–­ç»“æœ (2025-12-12 01:36):**
```
MySQL source_chunk: 493 æ¡
ES source_chunks:   493 æ¡ (æ•°é‡ä¸€è‡´ä½†å†…å®¹ä¸åŒæ­¥!)

æœªç´¢å¼•åˆ° ES çš„æ–‡æ¡£: 324 / 493 = 65.7%!

æœªç´¢å¼•æ–‡æ¡£ç¤ºä¾‹:
  - # Big Stone Gap (film)  â† Zero Recall
  - # Wolf Alice            â† Zero Recall  
  - # MacScan
  - # Hackers (film)
  - # Androscoggin Bank ColisÃ©e
  - ... è¿˜æœ‰ 319 ä¸ª
```

**å—å½±å“çš„ Zero Recall Cases:**
| Question ID | Question | Retrieved | Root Cause |
|-------------|----------|-----------|------------|
| 5a8e3ea9 | "The director of 'Big Stone Gap'..." | **0** | âš ï¸ **æ–‡æ¡£åœ¨MySQLä½†æœªç´¢å¼•åˆ°ES** |
| 5ae2070a | "Badly Drawn Boy or Wolf Alice?" | 3 | âš ï¸ **Wolf Alice æœªç´¢å¼•åˆ°ES** |
| 5adf37a9 | "VCU Rams 2011-12...founded?" | 10 | 2011-12 VCU Rams æ–‡æ¡£ä¸å­˜åœ¨ |

**é—®é¢˜åŸå› :**
- æ•°æ®é‡æ–°æå–åï¼Œ`_index_source_chunks_to_es()` æœªå¯¹æ‰€æœ‰æ–‡æ¡£æ‰§è¡Œ
- åªæœ‰éƒ¨åˆ†æ–‡æ¡£è¢«æ­£ç¡®åŒæ­¥åˆ° ES

---

### å†å² Zero Recall Case (å·²ä¿®å¤/å˜ä¸º Partial)

| Question ID | Question | Status |
|-------------|----------|--------|
| 5ae0d4c9 | "Roger O. Egeberg was Assistant Secretary..." | âœ… æœ¬æ¬¡æµ‹è¯•å·²å˜ä¸º **Partial Recall (50%)** |

**åŸé—®é¢˜åˆ†æ:**
- **Root Cause**: Multi-hop bridge question: Egeberg â†’ Nixon â†’ 1969-1974
- æœç´¢ç³»ç»Ÿå¬å›äº† "Assistant Secretary" ç›¸å…³çš„å…¶ä»–äººç‰©
- ä½†æœªæ‰¾åˆ°æ­£ç¡®çš„ Richard Nixon æ–‡æ¡£

**Database Verification:**
```
âœ… Roger O. Egeberg chunk EXISTS (id: 9da5e8af-6c19-46a6-b3c4-d7ea63a63ed1)
âœ… Richard Nixon chunk EXISTS (id: dca1c727-88d3-4fb6-a97e-71b155bc710d)
```

**Extracted Entities from Roger O. Egeberg:**
- person: Roger O. Egeberg
- role: Assistant Secretary for Health and Scientific Affairs
- organization: Department of Health, Education, and Welfare
- tags: Nixon â† **å…³é”®çº¿ç´¢å­˜åœ¨ä½†æœªè¢«æœ‰æ•ˆåˆ©ç”¨**

---

### Partial Recall Cases (16ä¸ª) - Pattern Analysis

#### Pattern 1: Comparison Questions (A vs B) - 6ä¸ª

| Question | Missing Entity |
|----------|---------------|
| "Which writer was from England, Henry Roth or Robert Erskine Childers?" | åªæ‰¾åˆ°å…¶ä¸­ä¸€ä¸ªä½œå®¶ |
| "Are Giuseppe Verdi and Ambroise Thomas both Opera composers?" | åªæ‰¾åˆ°å…¶ä¸­ä¸€ä¸ªä½œæ›²å®¶ |
| "Are Freakonomics and In the Realm of the Hackers both American documentaries?" | åªæ‰¾åˆ°å…¶ä¸­ä¸€éƒ¨ |
| "Which performance act has a higher instrument to person ratio, Badly Drawn Boy or Wolf Alice?" | åªæ‰¾åˆ°å…¶ä¸­ä¸€ä¸ªä¹é˜Ÿ |
| "Which dog's ancestors include Gordon and Irish Setters..." | åªæ‰¾åˆ°å…¶ä¸­ä¸€ç§ç‹— |

**Root Cause:** LLM å®ä½“æå–æ—¶åªè¯†åˆ«äº†éƒ¨åˆ†æ¯”è¾ƒå¯¹è±¡

**Solution Direction:** ä¼˜åŒ–æç¤ºè¯ï¼Œå¼ºè°ƒ "æå–æ‰€æœ‰è¢«æ¯”è¾ƒçš„å®ä½“"

---

#### Pattern 2: Multi-hop Bridge Questions - 10ä¸ª

| Question Type | Example |
|---------------|---------|
| Person â†’ Role â†’ Target | "What government position was held by the woman who portrayed Corliss Archer..." |
| Person â†’ Location â†’ Target | "Ralph Hefferline was a psychology professor at a university that is located in what city?" |
| Person â†’ Company â†’ Location | "Where is the company that Sachin Warrier worked for as a software engineer headquartered?" |
| Role â†’ Person â†’ Time | "Roger O. Egeberg was Assistant Secretary... president that served during what years?" |

**Root Cause:** 
1. ç¬¬ä¸€è·³å®ä½“å¬å›æˆåŠŸ
2. å¤šè·³æ‰©å±•æœªèƒ½æœ‰æ•ˆä¼ é€’åˆ°æ¡¥æ¥å®ä½“
3. æœ€ç»ˆç›®æ ‡å®ä½“æœªè¢«å¬å›

---

## ğŸ¯ Optimization Roadmap

### v1.5 - Score Threshold Experiment (2025-12-12) âŒ

**Hypothesis:** `score_threshold=0.45` å¤ªé«˜ï¼Œå¯¼è‡´ Zero Recall

**Experiment:** é™ä½ `score_threshold` ä» 0.45 â†’ 0.25

**Result:** âŒ **å¬å›ç‡åè€Œä¸‹é™ï¼**

| æŒ‡æ ‡ | Before (0.45) | After (0.25) | Change |
|------|---------------|--------------|--------|
| Overall Recall | **80%** | **65%** | **-15%** |
| Perfect Recall | 33 | 22 | -11 |
| Partial Recall | 14 | 21 | +7 |
| Zero Recall | 3 | 7 | +4 |

**Analysis:**
- é™ä½é˜ˆå€¼è®©æ›´å¤šä¸ç›¸å…³æ–‡æ¡£è¿›å…¥ PageRank
- PageRank æ’åºæ—¶ï¼Œå™ªéŸ³æ–‡æ¡£å¯èƒ½æ’åæ›´é«˜
- æŠŠçœŸæ­£ç›¸å…³çš„æ–‡æ¡£æŒ¤å‡º Top 10

**Conclusion:** ä¿æŒ `score_threshold=0.45`ï¼Œé—®é¢˜åœ¨å…¶ä»–åœ°æ–¹

---

### v1.6 - Deep Dive: Wolf Alice Zero Recall (2025-12-12) ğŸ”

**Case Study:** "Which performance act has a higher instrument to person ratio, Badly Drawn Boy or Wolf Alice?"

**Expected:** Wolf Alice, Badly Drawn Boy  
**Actual:** About a Boy (soundtrack), The Hour of Bewilderbeast (all wrong!)

**Debug Results:**

| é˜¶æ®µ | Wolf Alice çŠ¶æ€ | é—®é¢˜ |
|------|----------------|------|
| å‘é‡å¬å› | âœ… å¬å› (rank=5) | - |
| LLM è¯†åˆ« | âœ… æ­£ç¡®è¯†åˆ« | - |
| å®ä½“åŒ¹é… | âœ… ç›¸ä¼¼åº¦ 0.5984 | - |
| Event å¬å› | âœ… "Wolf Alice Band Formation..." | - |
| Chunk å…³è” | âœ… â†’ # Wolf Alice | - |
| **ç›¸ä¼¼åº¦æ£€æŸ¥** | âœ… 0.5469 > 0.45 | - |
| **æœ€ç»ˆç»“æœ** | âŒ æœªå‡ºç° | ??? |

**Root Cause Analysis:**
```
ç›¸ä¼¼åº¦è¿‡æ»¤: 120 â†’ 3 ä¸ªåŸæ–‡å— (é˜ˆå€¼=0.45)
```

ç†è®ºä¸Š Wolf Alice chunk ç›¸ä¼¼åº¦ 0.5469 åº”è¯¥é€šè¿‡ï¼Œä½†å®é™…è¢«è¿‡æ»¤ã€‚

**å¯èƒ½åŸå› :**
1. **LLM éç¡®å®šæ€§**: æ¯æ¬¡è¿è¡Œ query rewrite ä¸åŒï¼Œå½±å“ç›¸ä¼¼åº¦è®¡ç®—
2. **Expand é˜¶æ®µæƒé‡è¿‡æ»¤**: Wolf Alice å®ä½“æƒé‡ä½äºé˜ˆå€¼
3. **key_final åˆ—è¡¨é™åˆ¶**: Wolf Alice æœªè¿›å…¥æœ€ç»ˆ key åˆ—è¡¨

**æ•°æ®éªŒè¯:**
```
# Wolf Alice chunk ç›´æ¥æµ‹è¯• (é™æ€)
åŸå§‹ Query ç›¸ä¼¼åº¦: 0.5209 âœ…
é‡å†™ Query ç›¸ä¼¼åº¦: 0.5469 âœ…
```

**Next Steps:**
1. å¢åŠ æ—¥å¿—è¿½è¸ª Wolf Alice åœ¨æ¯ä¸ªé˜¶æ®µçš„æƒé‡å˜åŒ–
2. æ£€æŸ¥ `entities_per_hop` å’Œ `max_keys` å‚æ•°é™åˆ¶
3. è€ƒè™‘æ·»åŠ  "å…³é”®å®ä½“ä¿æŠ¤" æœºåˆ¶

---

### v1.7 - Zero Recall Root Cause Analysis (2025-12-12) ğŸ”

**æµ‹è¯•ç»“æœ:** 80% recall, 3 zero recall, 14 partial recall

**Zero Recall Cases è¯¦ç»†åˆ†æ:**

| Case | Question | Expected | æ ¹å›  |
|------|----------|----------|------|
| 1 | Big Stone Gap director in NY? | Big Stone Gap (film), Adriana Trigiani | **weight=0.10 < threshold=0.20** |
| 2 | Stage name Aladin consultant? | Eenasul Fateh, Management consulting | å¾…åˆ†æ |
| 3 | Wolf Alice vs Badly Drawn Boy? | Wolf Alice, Badly Drawn Boy | **ç›¸ä¼¼åº¦è¿‡æ»¤: 153â†’0 (é˜ˆå€¼0.45)** |

**Case 1 è¯¦ç»†åˆ†æ (Big Stone Gap):**
```
å‘é‡å¬å›: âœ… Big Stone Gap ç›¸ä¼¼åº¦ 0.5092
LLM è¯†åˆ«: âœ… æ­£ç¡®è¯†åˆ« "Big Stone Gap"
å®ä½“åŒ¹é…: âœ… æ‰¾åˆ° [work]Big Stone Gap, [location]Big Stone Gap

é—®é¢˜å‡ºç°:
Step6: Key 'Big Stone Gap': weight=0.1000, step=6
entity_weight_threshold: 0.2 â† Big Stone Gap è¢«è¿‡æ»¤ï¼

ç»“æœ:
- Big Stone Gap æœªè¿›å…¥ key_final
- 153 ä¸ªåŸæ–‡å—éƒ½ä¸ç›®æ ‡æ— å…³
- ç›¸ä¼¼åº¦è¿‡æ»¤: 153 â†’ 0
- æœ€ç»ˆè¿”å› 0 ä¸ªæ®µè½
```

**è§£å†³æ–¹æ¡ˆ:**

| ä¼˜åŒ– | å‚æ•° | å½“å‰å€¼ | å»ºè®®å€¼ | é¢„æœŸæ•ˆæœ |
|------|------|--------|--------|----------|
| é™ä½å®ä½“æƒé‡é˜ˆå€¼ | `entity_weight_threshold` | 0.2 | 0.1 | ä¿ç•™æ›´å¤šå®ä½“ |
| é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼ | `score_threshold` | 0.45 | 0.35 | å‡å°‘è¿‡æ»¤ |
| å¢åŠ å…³é”®å®ä½“ä¿æŠ¤ | N/A | N/A | é—®é¢˜ä¸­å‡ºç°çš„å®ä½“å¼ºåˆ¶ä¿ç•™ | ä¿è¯æ ¸å¿ƒå®ä½“ |

---

### v1.8 - æƒé‡å…¬å¼ä¼˜åŒ– (2025-12-12) âœ…

**é—®é¢˜åˆ†æï¼š**
- åŸå…¬å¼ `weight = sum(event_weights) Ã— similarity`
- event æ•°é‡å¤šçš„é€šç”¨å®ä½“ï¼ˆå¦‚ New York Cityï¼‰æƒé‡è¿‡é«˜
- æ ¸å¿ƒå®ä½“ï¼ˆå¦‚ Big Stone Gapï¼‰å›  event å°‘è¢«è¿‡æ»¤

**æ–°å…¬å¼ï¼š**
```python
# 1. Event è´¡çŒ®å½’ä¸€åŒ–ï¼ˆå¹³å‡å€¼æ›¿ä»£æ±‚å’Œï¼‰
avg_event_weight = sum(event_weights) / len(events)

# 2. è¯­ä¹‰ä¼˜å…ˆ + event è´¡çŒ®
base_weight = 0.7 Ã— similarity + 0.3 Ã— avg_event_weight

# 3. æ ¸å¿ƒå®ä½“ä¿æŠ¤ï¼ˆé—®é¢˜ä¸­ç›´æ¥æåˆ°çš„å®ä½“ +50%ï¼‰
core_boost = 1.5 if entity_name in query else 1.0
final_weight = base_weight Ã— core_boost
```

**æ•ˆæœï¼š**
| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | å˜åŒ– |
|------|--------|--------|------|
| Overall Recall | 80% | **83%** | **+3%** |
| Perfect Recall | 33 | 34 | +1 |
| Zero Recall | 3 | **1** | **-2** |

**ä¿®å¤çš„ Caseï¼š**
- âœ… Big Stone Gap (weight 0.10 â†’ 0.76)
- âœ… Wolf Alice (è¢«æ­£ç¡®å¬å›)

**å‰©ä½™ Zero Recallï¼š**
- VCU Rams 2011-12ï¼š**æ•°æ®æå–é—®é¢˜**ï¼ˆEvent æœªå…³è” "VCU Rams" å®ä½“ï¼‰

### Short-term (v1.5)

| Priority | Task | Expected Impact |
|----------|------|-----------------|
| ğŸ”´ High | ä¼˜åŒ– search prompt - å¼ºåˆ¶æå–æ‰€æœ‰æ¯”è¾ƒå¯¹è±¡ | +3-5% recall |
| ğŸ”´ High | å¢åŠ  max_results (10â†’15) | å…œåº•æ›´å¤šç»“æœ |
| ğŸŸ¡ Medium | é™ä½ LLM temperature (0.7â†’0.3) | å‡å°‘éšæœºæ€§ |

### Medium-term (v2.0)

| Task | Description |
|------|-------------|
| å¤šè·³æ‰©å±•ä¼˜åŒ– | å¢åŠ  hop depth æˆ–è°ƒæ•´å®ä½“æƒé‡ä¼ æ’­ |
| å®ä½“ç±»å‹ç»Ÿä¸€ | åŒä¸€ normalized_name åªä¿ç•™ä¸»ç±»å‹ |
| å®ä½“æ¶ˆæ­§ | å¤„ç†åŒåå®ä½“é—®é¢˜ |
| Query åˆ†è§£ | å°†å¤æ‚é—®é¢˜æ‹†åˆ†ä¸ºå­æŸ¥è¯¢ |

### Long-term (v3.0)

| Task | Description |
|------|-------------|
| Re-ranking æ¨¡å‹ | ä½¿ç”¨ cross-encoder é‡æ’ |
| Query Expansion | ä½¿ç”¨ LLM ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢å˜ä½“ |
| Hybrid Search | ç»“åˆ BM25 + Dense Retrieval |

---

## ğŸ“ Technical Notes

### LLM Non-determinism Issue

**Observation:** ç›¸åŒé…ç½®ä¸‹å¬å›ç‡æ³¢åŠ¨ 78-82%

**Cause:** LLM åœ¨é€‰æ‹© `focus_entity_types` æ—¶æœ‰éšæœºæ€§

**Mitigation:**
- é™ä½ temperature
- ä½¿ç”¨æ›´æ˜ç¡®çš„æç¤ºè¯
- è€ƒè™‘ä½¿ç”¨ fixed type list ä½œä¸º baseline

### Database Schema Reference

```sql
-- Key tables for search
source_chunk    -- åŸå§‹æ–‡æ¡£ç‰‡æ®µ
source_event    -- æå–çš„äº‹é¡¹
entity          -- å®ä½“ (name, type, normalized_name)
event_entity    -- äº‹é¡¹-å®ä½“å…³è”
```

### Entity Types in Use

```
person, organization, location, time, role, event, 
topic, action, product, tags (generic)
```

---

## ğŸ“ˆ Benchmark Comparison

| System | HotpotQA Recall | Notes |
|--------|-----------------|-------|
| **SAG (ours)** | **81-85%** | Focus entity types + PageRank (æ³¢åŠ¨èŒƒå›´) |
| BM25 baseline | ~60% | Traditional keyword matching |
| Dense Retrieval | ~70% | Single vector similarity |
| HippoRAG | 85%+ | SOTA multi-hop retrieval |

---

## ğŸ“‹ Test History Log

| Date | Time | Recall | Perfect | Partial | Zero | Notes |
|------|------|--------|---------|---------|------|-------|
| 2025-12-12 | 01:36 | **80%** | 33 | 14 | 3 | v1.4 æ•°æ®é‡æ–°æå–åï¼Œ65.7%æ–‡æ¡£æœªç´¢å¼•ES |
| 2025-12-12 | 01:10 | 81% | 34 | 13 | 3 | v1.3 stability test |
| 2025-12-12 | ~00:30 | 85% | 36 | 13 | 1 | v1.1 entity enhancement |
| 2025-12-11 | - | 82% | 33 | 16 | 1 | v1.0 baseline |

---

*Last updated: 2025-12-12*
