"""
è·¯å¾„åˆ†æå™¨ - è®¡ç®—ä» query åˆ° final event çš„æ‰€æœ‰å®Œæ•´è·¯å¾„

åŸºäºçº¿ç´¢(clues)æ•°æ®ï¼Œä½¿ç”¨ DFS åæ¨ç®—æ³•è®¡ç®—æ‰€æœ‰å®Œæ•´æ¨ç†è·¯å¾„ï¼Œ
æ”¯æŒæœ€çŸ­è·¯å¾„ã€æœ€é•¿è·¯å¾„åˆ†æï¼Œä¸ºå‰ç«¯çŸ¥è¯†å›¾è°±ç²¾ç®€æ¨¡å¼æä¾›æ•°æ®æ”¯æŒã€‚

æ³¨æ„ï¼šæ­¤æ¨¡å—ä¸ä¼šä¿®æ”¹ä¼ å…¥çš„ clues æ•°æ®ï¼Œæ‰€æœ‰æ“ä½œéƒ½åŸºäºæ·±æ‹·è´ã€‚
"""

import copy
import uuid
from collections import defaultdict
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Set, Tuple

from dataflow.utils import get_logger

logger = get_logger("search.path_analyzer")


@dataclass
class PathNode:
    """
    è·¯å¾„èŠ‚ç‚¹

    Attributes:
        id: èŠ‚ç‚¹å”¯ä¸€ID
        type: èŠ‚ç‚¹ç±»å‹ (query, entity, event, section)
        content: èŠ‚ç‚¹æ˜¾ç¤ºå†…å®¹
        stage: æ‰€å±é˜¶æ®µ (recall, expand, rerank)
        hop: è·³æ•°ï¼ˆExpand é˜¶æ®µï¼‰
        metadata: é™„åŠ å…ƒæ•°æ®
    """
    id: str
    type: str
    content: str
    stage: str
    hop: int = 0
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "type": self.type,
            "content": self.content,
            "stage": self.stage,
            "hop": self.hop,
            "metadata": self.metadata,
        }


@dataclass
class PathLine:
    """
    å®Œæ•´è·¯å¾„çº¿ï¼ˆä» query åˆ° final eventï¼‰

    ä¸€æ¡ line ä»£è¡¨ä¸€æ¡å®Œæ•´çš„æ¨ç†è·¯å¾„

    Attributes:
        id: è·¯å¾„å”¯ä¸€ID
        nodes: è·¯å¾„ä¸Šçš„æ‰€æœ‰èŠ‚ç‚¹ï¼ˆæœ‰åºï¼Œä» query åˆ° eventï¼‰
        clue_ids: å¯¹åº”çš„çº¿ç´¢IDåˆ—è¡¨
        total_confidence: è·¯å¾„æ€»ç½®ä¿¡åº¦
        length: è·¯å¾„é•¿åº¦ï¼ˆè¾¹æ•°ï¼‰
        stages: ç»è¿‡çš„é˜¶æ®µåˆ—è¡¨
        event_id: æœ€ç»ˆäº‹é¡¹çš„æ•°æ®åº“ID
    """
    id: str
    nodes: List[PathNode]
    clue_ids: List[str]
    total_confidence: float
    length: int
    stages: List[str]
    event_id: str

    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "nodes": [node.to_dict() for node in self.nodes],
            "clue_ids": self.clue_ids,
            "total_confidence": self.total_confidence,
            "length": self.length,
            "stages": self.stages,
            "event_id": self.event_id,
        }


@dataclass
class PathAnalysisResult:
    """
    è·¯å¾„åˆ†æç»“æœ

    Attributes:
        min_lines: æ¯ä¸ªäº‹é¡¹çš„æœ€çŸ­è·¯å¾„ï¼ˆå¯Œå«å®Œæ•´æ•°æ®æ ¼å¼ï¼‰
        max_lines: æ¯ä¸ªäº‹é¡¹çš„æœ€é•¿è·¯å¾„ï¼ˆå¯Œå«å®Œæ•´æ•°æ®æ ¼å¼ï¼‰
        entitys: æŒ‰è·³æ•°åˆ†ç»„çš„å®ä½“ç»Ÿè®¡
        rerank_lines: æ¯ä¸ªäº‹é¡¹çš„æ‰€æœ‰è·¯å¾„ï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰
    """
    min_lines: Dict[str, List[Dict[str, Any]]]  # {"event-id": [{"query": ...}, {"entity": ...}, {"event": ...}]}
    max_lines: Dict[str, List[Dict[str, Any]]]  # {"event-id": [{"query": ...}, {"entity": ...}, {"event": ...}]}
    entitys: Dict[str, List[Dict[str, Any]]]  # {"0": [], "1": [], "2": []}
    rerank_lines: Dict[str, List[List[Dict[str, Any]]]]  # {"event-id": [[path1], [path2], ...]}

    def to_dict(self) -> Dict[str, Any]:
        return {
            "min_lines": self.min_lines,
            "max_lines": self.max_lines,
            "entitys": self.entitys,
            "rerank_lines": self.rerank_lines,
        }


class PathAnalyzer:
    """
    è·¯å¾„åˆ†æå™¨

    ä»çº¿ç´¢åˆ—è¡¨ä¸­è®¡ç®—æ‰€æœ‰å®Œæ•´è·¯å¾„ï¼ˆquery â†’ final eventï¼‰
    ä½¿ç”¨ DFS åæ¨ç®—æ³•ï¼Œä» Rerank é˜¶æ®µçš„ final çº¿ç´¢å¼€å§‹ï¼Œ
    åå‘è¿½æº¯åˆ° Query èŠ‚ç‚¹ã€‚
    """

    def __init__(self, clues: List[Dict[str, Any]]):
        """
        åˆå§‹åŒ–è·¯å¾„åˆ†æå™¨

        Args:
            clues: çº¿ç´¢åˆ—è¡¨ï¼ˆæ¥è‡ª config.all_cluesï¼‰

        æ³¨æ„ï¼šä¼šå¯¹ clues è¿›è¡Œæ·±æ‹·è´ï¼Œä¸ä¼šä¿®æ”¹åŸå§‹æ•°æ®
        """
        # æ·±æ‹·è´ï¼Œç¡®ä¿ä¸ä¿®æ”¹åŸå§‹æ•°æ®
        self.clues = copy.deepcopy(clues)
        self.logger = get_logger("search.path_analyzer")

        # å›¾ç»“æ„
        self.forward_graph: Dict[str, List[Tuple[str, Dict]]] = defaultdict(list)
        self.reverse_graph: Dict[str, List[Tuple[str, Dict]]] = defaultdict(list)
        self.nodes: Dict[str, Dict] = {}
        self.final_clues: List[Dict] = []
        self.query_nodes: Set[str] = set()

        # æ„å»ºå›¾
        self._build_graph()

    def _build_graph(self):
        """æ„å»ºé‚»æ¥è¡¨å’Œåå‘é‚»æ¥è¡¨"""
        # ğŸ” è¯Šæ–­ï¼šæ£€æµ‹å¾ªç¯å¼•ç”¨
        potential_cycles = []

        for clue in self.clues:
            from_node = clue.get("from", {})
            to_node = clue.get("to", {})
            from_id = from_node.get("id")
            to_id = to_node.get("id")

            if not from_id or not to_id:
                continue

            # å­˜å‚¨èŠ‚ç‚¹ä¿¡æ¯
            self.nodes[from_id] = from_node
            self.nodes[to_id] = to_node

            # æ„å»ºæ­£å‘å’Œåå‘å›¾
            self.forward_graph[from_id].append((to_id, clue))
            self.reverse_graph[to_id].append((from_id, clue))

            # è¯†åˆ« query èŠ‚ç‚¹
            if from_node.get("type") == "query":
                self.query_nodes.add(from_id)

            # è¯†åˆ« final çº¿ç´¢ï¼ˆRerank é˜¶æ®µçš„æœ€ç»ˆç»“æœï¼‰
            if clue.get("display_level") == "final" and clue.get("stage") == "rerank":
                self.final_clues.append(clue)

            # ğŸ” è¯Šæ–­ï¼šæ£€æµ‹æ½œåœ¨çš„åŒå‘è¾¹ï¼ˆå¯èƒ½å¯¼è‡´å¾ªç¯ï¼‰
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨åå‘è¾¹ï¼što_id â†’ from_id
            if to_id in self.forward_graph:
                for existing_to, existing_clue in self.forward_graph[to_id]:
                    if existing_to == from_id:
                        potential_cycles.append({
                            "node1_id": from_id[:20],
                            "node1_type": from_node.get("type"),
                            "node1_content": from_node.get("content", "")[:20],
                            "node2_id": to_id[:20],
                            "node2_type": to_node.get("type"),
                            "node2_content": to_node.get("content", "")[:20],
                            "clue1_stage": clue.get("stage"),
                            "clue2_stage": existing_clue.get("stage"),
                        })

        self.logger.debug(
            f"å›¾æ„å»ºå®Œæˆ: {len(self.nodes)} èŠ‚ç‚¹, "
            f"{len(self.clues)} è¾¹, "
            f"{len(self.final_clues)} æ¡ final çº¿ç´¢, "
            f"{len(self.query_nodes)} ä¸ª query èŠ‚ç‚¹"
        )

        # ğŸ” è¾“å‡ºå¾ªç¯æ£€æµ‹ç»“æœ
        if potential_cycles:
            self.logger.warning(
                f"ğŸ” æ£€æµ‹åˆ° {len(potential_cycles)} å¯¹æ½œåœ¨çš„åŒå‘è¾¹ï¼ˆå¯èƒ½å¯¼è‡´è·¯å¾„æ–­è£‚ï¼‰:"
            )
            for cycle in potential_cycles[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                self.logger.warning(
                    f"  â€¢ {cycle['node1_type']} '{cycle['node1_content']}' ({cycle['node1_id']}...) "
                    f"â†” {cycle['node2_type']} '{cycle['node2_content']}' ({cycle['node2_id']}...) "
                    f"[stage: {cycle['clue1_stage']} â†” {cycle['clue2_stage']}]"
                )
            if len(potential_cycles) > 5:
                self.logger.warning(f"  ... è¿˜æœ‰ {len(potential_cycles) - 5} å¯¹åŒå‘è¾¹æœªæ˜¾ç¤º")
        else:
            self.logger.info("âœ… æœªæ£€æµ‹åˆ°åŒå‘è¾¹ï¼Œå›¾ç»“æ„æ­£å¸¸")

    def analyze(self, target_event_ids: Optional[List[str]] = None) -> PathAnalysisResult:
        """
        åˆ†ææ‰€æœ‰è·¯å¾„

        Args:
            target_event_ids: ç›®æ ‡äº‹é¡¹IDåˆ—è¡¨ï¼ˆä»…åˆ†æè¿™äº›äº‹é¡¹çš„è·¯å¾„ï¼‰
                             å¦‚æœä¸º Noneï¼Œåˆ™åˆ†ææ‰€æœ‰ final çº¿ç´¢

        Returns:
            PathAnalysisResult: åŒ…å«æ‰€æœ‰è·¯å¾„ã€æœ€çŸ­/æœ€é•¿è·¯å¾„å’Œç»Ÿè®¡ä¿¡æ¯
        """
        all_lines: List[PathLine] = []

        # ğŸ”§ æ ¹æ® target_event_ids è¿‡æ»¤ final_clues
        if target_event_ids is not None:
            # å°†ç›®æ ‡äº‹é¡¹IDè½¬ä¸ºé›†åˆï¼Œæ–¹ä¾¿å¿«é€ŸæŸ¥æ‰¾
            target_id_set = set(target_event_ids)
            filtered_final_clues = []

            for clue in self.final_clues:
                to_node = clue.get("to", {})
                event_id = to_node.get("event_id") or to_node.get("id")
                if event_id in target_id_set:
                    filtered_final_clues.append(clue)

            self.logger.info(
                f"å¼€å§‹è·¯å¾„åˆ†æ: ä» {len(self.final_clues)} æ¡ final çº¿ç´¢ä¸­ç­›é€‰å‡º "
                f"{len(filtered_final_clues)} æ¡ç›®æ ‡äº‹é¡¹çš„çº¿ç´¢"
            )
            final_clues_to_analyze = filtered_final_clues
        else:
            self.logger.info(f"å¼€å§‹è·¯å¾„åˆ†æ: {len(self.final_clues)} æ¡ final çº¿ç´¢")
            final_clues_to_analyze = self.final_clues

        # ä»æ¯ä¸ª final çº¿ç´¢åæ¨å®Œæ•´è·¯å¾„
        for final_clue in final_clues_to_analyze:
            to_node = final_clue.get("to", {})
            event_id = to_node.get("event_id") or to_node.get("id")

            # DFS åæ¨æ‰€æœ‰è·¯å¾„
            paths = self._find_all_paths_to_query(final_clue)

            # æ”¹ä¸º info çº§åˆ«,æ–¹ä¾¿æ’æŸ¥è·¯å¾„ä¸¢å¤±é—®é¢˜
            if len(paths) == 0:
                # ğŸ”§ è°ƒè¯•ï¼šè¾“å‡º final_clue çš„è¯¦ç»†ä¿¡æ¯
                from_node = final_clue.get("from", {})
                self.logger.warning(
                    f"âš ï¸ Final event {event_id}: æ‰¾åˆ° 0 æ¡è·¯å¾„"
                )
                self.logger.warning(
                    f"   Final clue: {from_node.get('type')}(id={from_node.get('id')[:30]}...) "
                    f"â†’ {to_node.get('type')}(id={to_node.get('id')[:30]}...)"
                )
                # æ£€æŸ¥ from_node æ˜¯å¦æœ‰çˆ¶èŠ‚ç‚¹
                from_id = from_node.get("id")
                parents = self.reverse_graph.get(from_id, [])
                self.logger.warning(
                    f"   FromèŠ‚ç‚¹ '{from_id[:30]}...' çš„çˆ¶èŠ‚ç‚¹æ•°é‡: {len(parents)}"
                )
                if len(parents) == 0:
                    self.logger.warning(
                        f"   âŒ FromèŠ‚ç‚¹æ²¡æœ‰çˆ¶èŠ‚ç‚¹ï¼Œè·¯å¾„ä¸­æ–­ï¼"
                    )
                    # è¾“å‡º from èŠ‚ç‚¹çš„è¯¦ç»†ä¿¡æ¯
                    self.logger.warning(
                        f"   FromèŠ‚ç‚¹è¯¦æƒ…: type={from_node.get('type')}, "
                        f"content={from_node.get('content', '')[:30]}, "
                        f"stage={final_clue.get('stage')}"
                    )
                else:
                    # è¾“å‡ºçˆ¶èŠ‚ç‚¹çš„è¯¦ç»†ä¿¡æ¯
                    parent_details = []
                    for parent_id, parent_clue in parents[:3]:
                        parent_node_data = self.nodes.get(parent_id, {})
                        parent_type = parent_node_data.get("type", "unknown")
                        parent_stage = parent_clue.get('stage')
                        parent_content = parent_node_data.get('content', '')[:20]
                        parent_details.append({
                            'id': parent_id[:20],
                            'type': parent_type,
                            'stage': parent_stage,
                            'content': parent_content
                        })

                    self.logger.warning(
                        f"   çˆ¶èŠ‚ç‚¹åˆ—è¡¨ (å‰3ä¸ª): {parent_details}"
                    )

                    # ğŸ”§ æ£€æŸ¥ï¼šå¦‚æœçˆ¶èŠ‚ç‚¹æ˜¯ eventï¼Œç»§ç»­æ£€æŸ¥è¿™ä¸ª event æœ‰æ²¡æœ‰çˆ¶èŠ‚ç‚¹
                    for parent_id, parent_clue in parents[:1]:
                        parent_node_data = self.nodes.get(parent_id, {})
                        parent_type = parent_node_data.get("type", "unknown")
                        if parent_type == "event":
                            # æ£€æŸ¥è¿™ä¸ª event èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹
                            event_parents = self.reverse_graph.get(parent_id, [])
                            self.logger.warning(
                                f"   â†’ çˆ¶èŠ‚ç‚¹æ˜¯ event '{parent_id[:20]}...', "
                                f"å®ƒçš„çˆ¶èŠ‚ç‚¹æ•°é‡: {len(event_parents)}"
                            )
                            if len(event_parents) == 0:
                                self.logger.error(
                                    f"   âŒ Event çˆ¶èŠ‚ç‚¹æ²¡æœ‰æ›´ä¸Šå±‚çš„çˆ¶èŠ‚ç‚¹ï¼Œè·¯å¾„åœ¨æ­¤ä¸­æ–­ï¼"
                                )
                            else:
                                # è¾“å‡º event çš„çˆ¶èŠ‚ç‚¹
                                event_parent_details = []
                                for ep_id, ep_clue in event_parents[:3]:
                                    ep_data = self.nodes.get(ep_id, {})
                                    event_parent_details.append({
                                        'id': ep_id[:20],
                                        'type': ep_data.get('type'),
                                        'stage': ep_clue.get('stage')
                                    })
                                self.logger.warning(
                                    f"   â†’ Event çš„çˆ¶èŠ‚ç‚¹: {event_parent_details}"
                                )

                                # ğŸ”§ ç»§ç»­æ£€æŸ¥ event çš„çˆ¶èŠ‚ç‚¹ï¼ˆentityï¼‰æ˜¯å¦æœ‰çˆ¶èŠ‚ç‚¹
                                for ep_id, ep_clue in event_parents[:1]:
                                    ep_data = self.nodes.get(ep_id, {})
                                    ep_type = ep_data.get('type')
                                    entity_parents = self.reverse_graph.get(ep_id, [])
                                    self.logger.warning(
                                        f"   â†’ â†’ Entity '{ep_id[:20]}...' (type={ep_type}) çš„çˆ¶èŠ‚ç‚¹æ•°é‡: {len(entity_parents)}"
                                    )
                                    if len(entity_parents) == 0:
                                        self.logger.error(
                                            f"   âŒâŒ Entity èŠ‚ç‚¹æ²¡æœ‰çˆ¶èŠ‚ç‚¹ï¼Œè·¯å¾„åœ¨æ­¤å½»åº•ä¸­æ–­ï¼"
                                        )
                                    else:
                                        # æ˜¾ç¤ºè¿™ä¸ªå®ä½“çš„çˆ¶èŠ‚ç‚¹
                                        entity_parent_details = []
                                        for eep_id, eep_clue in entity_parents[:3]:
                                            eep_data = self.nodes.get(eep_id, {})
                                            entity_parent_details.append({
                                                'id': eep_id[:20],
                                                'type': eep_data.get('type'),
                                                'stage': eep_clue.get('stage')
                                            })
                                        self.logger.warning(
                                            f"   â†’ â†’ Entity çš„çˆ¶èŠ‚ç‚¹: {entity_parent_details}"
                                        )
            else:
                self.logger.debug(
                    f"Final event {event_id}: æ‰¾åˆ° {len(paths)} æ¡è·¯å¾„"
                )

            for path_nodes, path_clues in paths:
                # è®¡ç®—è·¯å¾„ç½®ä¿¡åº¦ï¼ˆè¾¹ç½®ä¿¡åº¦çš„ä¹˜ç§¯ï¼‰
                confidences = [c.get("confidence", 1.0) for c in path_clues]
                total_confidence = 1.0
                for conf in confidences:
                    total_confidence *= conf

                # æå–ç»è¿‡çš„é˜¶æ®µï¼ˆå»é‡ä¿åºï¼‰
                stages = []
                for clue in path_clues:
                    stage = clue.get("stage")
                    if stage and (not stages or stages[-1] != stage):
                        stages.append(stage)

                # ğŸ†• è°ƒè¯•ï¼šæ£€æŸ¥è·¯å¾„ä¸­çš„èŠ‚ç‚¹ç±»å‹å’Œè·³æ•°
                node_types = [n.type for n in path_nodes]
                entity_hops = [n.hop for n in path_nodes if n.type == "entity"]

                if len(paths) <= 3 and len(all_lines) <= 10:  # åªåœ¨å‰é¢å‡ æ¡è·¯å¾„è¾“å‡ºè¯¦ç»†æ—¥å¿—
                    self.logger.debug(
                        f"è·¯å¾„æ„å»º: èŠ‚ç‚¹ç±»å‹={node_types}, "
                        f"å®ä½“è·³æ•°={entity_hops}, é˜¶æ®µ={stages}"
                    )
                    # ğŸ› è¾“å‡ºæ¯ä¸ªå®ä½“èŠ‚ç‚¹çš„è¯¦ç»†ä¿¡æ¯
                    for idx, node in enumerate(path_nodes):
                        if node.type == "entity":
                            self.logger.debug(
                                f"  å®ä½“[{idx}]: id={node.id[:30]}, "
                                f"content={node.content[:20]}, hop={node.hop}, stage={node.stage}"
                            )

                line = PathLine(
                    id=str(uuid.uuid4()),
                    nodes=path_nodes,
                    clue_ids=[c.get("id", "") for c in path_clues],
                    total_confidence=round(total_confidence, 4),
                    length=len(path_clues),
                    stages=stages,
                    event_id=event_id,  # æ”¹ä¸º event_id
                )
                all_lines.append(line)

        # å»é‡
        all_lines = self._deduplicate_lines(all_lines)

        # ğŸ†• ç»Ÿè®¡ entitysï¼ˆæŒ‰è·³æ•°åˆ†ç»„ï¼‰- ä¼ å…¥æ‰€æœ‰è·¯å¾„ç”¨äºç»Ÿè®¡
        entitys = self._build_entitys_by_hop(all_lines)

        # ğŸ†• æ„å»º rerank_linesï¼ˆæ‰€æœ‰è·¯å¾„çš„å¯Œå«æ•°æ®ï¼‰- ä½¿ç”¨ all_lines
        rerank_lines = self._build_all_event_lines(all_lines)

        # ğŸ†• ä» rerank_lines ä¸­ç›´æ¥æå– min_lines å’Œ max_lines
        min_lines = self._extract_min_lines_from_rerank(rerank_lines)
        max_lines = self._extract_max_lines_from_rerank(rerank_lines)

        # æ£€æŸ¥æ˜¯å¦æœ‰äº‹é¡¹è·¯å¾„ä¸¢å¤±
        # ğŸ”§ ä¿®å¤ï¼šåº”è¯¥ç»Ÿè®¡æœ‰å¤šå°‘ä¸ªå”¯ä¸€äº‹é¡¹æœ‰ final çº¿ç´¢
        final_event_ids = set()
        for clue in final_clues_to_analyze:
            to_node = clue.get("to", {})
            event_id = to_node.get("event_id") or to_node.get("id")
            final_event_ids.add(event_id)

        final_event_count = len(final_event_ids)
        found_event_count = len(min_lines)

        if final_event_count != found_event_count:
            missing_event_ids = final_event_ids - set(min_lines.keys())
            self.logger.warning(
                f"âš ï¸ è·¯å¾„æ„å»ºå·®å¼‚: ç›®æ ‡ {final_event_count} ä¸ªäº‹é¡¹, "
                f"ä½†åªæ‰¾åˆ° {found_event_count} ä¸ªäº‹é¡¹çš„å®Œæ•´è·¯å¾„ "
                f"(ä¸¢å¤± {final_event_count - found_event_count} ä¸ª)"
            )
            if missing_event_ids:
                self.logger.warning(
                    f"   ç¼ºå¤±è·¯å¾„çš„äº‹é¡¹ID: {list(missing_event_ids)[:5]}"
                )
        else:
            self.logger.info(
                f"âœ… æ‰€æœ‰ {final_event_count} ä¸ªç›®æ ‡äº‹é¡¹éƒ½æ‰¾åˆ°äº†å®Œæ•´è·¯å¾„"
            )

        self.logger.info(
            f"è·¯å¾„åˆ†æå®Œæˆ: æ€»è·¯å¾„æ•°={len(all_lines)}, "
            f"äº‹é¡¹æ•°={len(min_lines)}"
        )

        return PathAnalysisResult(
            min_lines=min_lines,  # å¯Œå«å®Œæ•´æ•°æ®æ ¼å¼ï¼ˆæœ€çŸ­è·¯å¾„ï¼‰ï¼š{"event-id": [{"query": ...}, ...]}
            max_lines=max_lines,  # å¯Œå«å®Œæ•´æ•°æ®æ ¼å¼ï¼ˆæœ€é•¿è·¯å¾„ï¼‰ï¼š{"event-id": [{"query": ...}, ...]}
            entitys=entitys,
            rerank_lines=rerank_lines,  # æ‰€æœ‰è·¯å¾„ï¼š{"event-id": [[path1], [path2], ...]}
        )

    def _find_all_paths_to_query(
        self,
        final_clue: Dict,
        max_depth: int = 10,
    ) -> List[Tuple[List[PathNode], List[Dict]]]:
        """
        ä» final çº¿ç´¢åæ¨åˆ° query çš„æ‰€æœ‰è·¯å¾„

        ä½¿ç”¨ DFS å›æº¯ç®—æ³•

        Args:
            final_clue: æœ€ç»ˆçº¿ç´¢
            max_depth: æœ€å¤§æœç´¢æ·±åº¦ï¼ˆé˜²æ­¢æ­»å¾ªç¯ï¼‰

        Returns:
            List of (èŠ‚ç‚¹åˆ—è¡¨, çº¿ç´¢åˆ—è¡¨) å…ƒç»„
        """
        all_paths = []

        def dfs(
            current_node_id: str,
            path_nodes: List[PathNode],
            path_clues: List[Dict],
            visited: Set[str],
            depth: int,
        ):
            # ğŸ” è°ƒè¯•ï¼šè®°å½• DFS è¿›å…¥
            current_node_data = self.nodes.get(current_node_id, {})
            current_node_type = current_node_data.get("type", "unknown")
            current_node_content = current_node_data.get("content", "")[:20]

            # ğŸ”§ ç§»é™¤æ·±åº¦é™åˆ¶ï¼Œä¾èµ– visited é›†åˆé˜²æ­¢å¾ªç¯
            # if depth > max_depth:
            #     self.logger.warning(
            #         f"âš ï¸ DFSè¾¾åˆ°æœ€å¤§æ·±åº¦{max_depth}: node={current_node_id[:20]}... "
            #         f"(type={current_node_type}, content='{current_node_content}')"
            #     )
            #     return

            # åˆ°è¾¾ origin query èŠ‚ç‚¹ï¼Œæ‰¾åˆ°ä¸€æ¡å®Œæ•´è·¯å¾„
            # ğŸ”§ ä¿®å¤ï¼šåªæœ‰ category="origin" çš„ query æ‰æ˜¯çœŸæ­£çš„èµ·ç‚¹
            # å¦‚æœæ˜¯ rewrite queryï¼Œéœ€è¦ç»§ç»­å¾€ä¸Šè¿½æº¯åˆ° origin query
            if current_node_id in self.query_nodes:
                node_data = self.nodes.get(current_node_id, {})
                category = node_data.get("category", "origin")

                # åªæœ‰ origin query æ‰åœæ­¢
                if category == "origin":
                    # è·¯å¾„æ˜¯åå‘çš„ï¼Œéœ€è¦ç¿»è½¬
                    all_paths.append((
                        list(reversed(path_nodes)),
                        list(reversed(path_clues))
                    ))
                    self.logger.debug(
                        f"âœ… DFSæ‰¾åˆ°å®Œæ•´è·¯å¾„: é•¿åº¦={len(path_nodes)}, depth={depth}"
                    )
                    return
                # rewrite query ç»§ç»­å¾€ä¸Šè¿½æº¯

            # è·å–æ‰€æœ‰çˆ¶èŠ‚ç‚¹
            parents = self.reverse_graph.get(current_node_id, [])

            # ğŸ” è°ƒè¯•ï¼šè®°å½•çˆ¶èŠ‚ç‚¹æ•°é‡
            if len(parents) == 0:
                self.logger.warning(
                    f"âš ï¸ DFSé‡åˆ°æ–­ç‚¹ï¼ˆæ— çˆ¶èŠ‚ç‚¹ï¼‰: node={current_node_id[:20]}... "
                    f"(type={current_node_type}, content='{current_node_content}'), depth={depth}"
                )

            # ğŸ”§ ä¿®å¤ï¼šå¦‚æœå½“å‰èŠ‚ç‚¹æ˜¯ eventï¼ˆä¸”ä¸æ˜¯æœ€ç»ˆçš„ final eventï¼‰ï¼Œ
            # éœ€è¦ç»§ç»­å¾€ä¸Šè¿½æº¯ï¼Œå› ä¸ºè·¯å¾„å¯èƒ½æ˜¯ query â†’ entity â†’ event â†’ entity â†’ final_event
            current_node_data = self.nodes.get(current_node_id, {})
            current_node_type = current_node_data.get("type", "")

            for parent_id, clue in parents:
                if parent_id in visited:
                    # ğŸ”§ è°ƒè¯•ï¼šè®°å½•é‡åˆ°ç¯çš„æƒ…å†µ
                    parent_data = self.nodes.get(parent_id, {})
                    self.logger.warning(
                        f"âš ï¸ DFSé‡åˆ°ç¯: current_node={current_node_id[:20]}..., "
                        f"parent_id={parent_id[:30]}..., "
                        f"type={parent_data.get('type')}, "
                        f"content={parent_data.get('content', '')[:20]}, "
                        f"å½“å‰æ·±åº¦={depth}, "
                        f"visited={[vid[:8] for vid in list(visited)[:5]]}"
                    )
                    continue  # é¿å…ç¯

                # ğŸ”§ ä¿®å¤ï¼šä» clue çš„ from èŠ‚ç‚¹è·å–å‡†ç¡®çš„ hop å€¼
                # parent æ˜¯åå‘è¿½æº¯ï¼Œæ‰€ä»¥ parent_id å¯¹åº” clue çš„ from èŠ‚ç‚¹
                clue_from = clue.get("from", {})
                parent_data = self.nodes.get(parent_id, {})

                # ä¼˜å…ˆä½¿ç”¨ clue ä¸­çš„ hopï¼ˆæ›´å‡†ç¡®ï¼‰ï¼Œfallback åˆ° parent_data
                parent_hop = clue_from.get("hop", parent_data.get("hop", 0))

                # ğŸ› è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥ hop æ¥æº
                if parent_data.get("type") == "entity" and clue_from.get("hop") != parent_data.get("hop"):
                    self.logger.debug(
                        f"âš ï¸ Hop ä¸ä¸€è‡´: entity={parent_id[:20]}..., "
                        f"clue.from.hop={clue_from.get('hop')}, "
                        f"nodes.hop={parent_data.get('hop')}, "
                        f"ä½¿ç”¨ clue.from.hop={parent_hop}"
                    )

                parent_node = PathNode(
                    id=parent_id,
                    type=parent_data.get("type", "unknown"),
                    content=parent_data.get("content", ""),
                    stage=clue.get("stage", ""),
                    hop=parent_hop,  # ğŸ”§ ä½¿ç”¨ä» clue ä¸­æå–çš„ hop
                    metadata={
                        "confidence": clue.get("confidence", 0),
                        "relation": clue.get("relation", ""),
                    }
                )

                # ç»§ç»­ DFS
                visited.add(parent_id)
                path_nodes.append(parent_node)
                path_clues.append(clue)

                dfs(parent_id, path_nodes, path_clues, visited, depth + 1)

                # å›æº¯
                path_nodes.pop()
                path_clues.pop()
                visited.remove(parent_id)

        # ä» final çº¿ç´¢çš„ to èŠ‚ç‚¹å¼€å§‹
        to_node = final_clue.get("to", {})
        to_id = to_node.get("id")

        if not to_id:
            return []

        # åˆå§‹åŒ–ï¼šå…ˆæ·»åŠ  final event èŠ‚ç‚¹
        initial_node = PathNode(
            id=to_id,
            type=to_node.get("type", "event"),
            content=to_node.get("content", ""),
            stage="rerank",
            hop=0,
        )

        # ä» from èŠ‚ç‚¹å¼€å§‹åæ¨
        from_node = final_clue.get("from", {})
        from_id = from_node.get("id")

        if not from_id:
            return []

        from_path_node = PathNode(
            id=from_id,
            type=from_node.get("type", "entity"),
            content=from_node.get("content", ""),
            stage=final_clue.get("stage", "rerank"),
            hop=from_node.get("hop", 0),
            metadata={
                "confidence": final_clue.get("confidence", 0),
                "relation": final_clue.get("relation", ""),
            }
        )

        # å¼€å§‹ DFS
        # ğŸ”§ ä¿®å¤ï¼šfrom_id ä¸åº”è¯¥åœ¨åˆå§‹ visited ä¸­ï¼Œå› ä¸ºè·¯å¾„å¯èƒ½å›åˆ°åŒä¸€ä¸ªå®ä½“
        # æ¯”å¦‚ï¼šentity_A â†’ event1 â†’ entity_A â†’ queryï¼ˆé€šè¿‡ä¸åŒçš„çº¿ç´¢å›åˆ°åŒä¸€å®ä½“æ˜¯å…è®¸çš„ï¼‰
        dfs(
            from_id,
            [initial_node, from_path_node],
            [final_clue],
            {to_id},  # åªåŒ…å«æœ€ç»ˆäº‹é¡¹èŠ‚ç‚¹ï¼Œä¸åŒ…å« from_id
            depth=0,
        )

        return all_paths

    def _deduplicate_lines(self, lines: List[PathLine]) -> List[PathLine]:
        """
        å»é‡ï¼šç›¸åŒèŠ‚ç‚¹åºåˆ—çš„è·¯å¾„åªä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„

        Args:
            lines: è·¯å¾„åˆ—è¡¨

        Returns:
            å»é‡åçš„è·¯å¾„åˆ—è¡¨
        """
        seen: Dict[Tuple[str, ...], PathLine] = {}

        for line in lines:
            # ç”¨èŠ‚ç‚¹IDåºåˆ—ä½œä¸ºå»é‡é”®
            key = tuple(n.id for n in line.nodes)

            if key not in seen or line.total_confidence > seen[key].total_confidence:
                seen[key] = line

        return list(seen.values())

    def _build_entitys_by_hop(self, lines: List[PathLine]) -> Dict[str, List[Dict[str, Any]]]:
        """
        æŒ‰è·³æ•°åˆ†ç»„å®ä½“ï¼ˆå»é‡ï¼‰- ä»æ‰€æœ‰çº¿ç´¢ä¸­æå–

        ä»åŸå§‹ clues ä¸­æå– Recall å’Œ Expand é˜¶æ®µçš„ final å®ä½“ï¼š
        - Recall é˜¶æ®µï¼šstage='recall', display_level='final', to.type='entity', hop=0
        - Expand é˜¶æ®µï¼šstage='expand', display_level='final', to.type='entity', hop>=1

        Args:
            lines: è·¯å¾„åˆ—è¡¨ï¼ˆå®é™…ä¸ä½¿ç”¨ï¼Œæ”¹ä¸ºä½¿ç”¨ self.cluesï¼‰

        Returns:
            {"0": [entity1, entity2, ...], "1": [...], "2": [...]}
            - "0": Recall å¬å›çš„ final å®ä½“
            - "1": Expand ç¬¬1è·³å¬å›çš„ final å®ä½“
            - "2": Expand ç¬¬2è·³å¬å›çš„ final å®ä½“
        """
        # æŒ‰è·³æ•°åˆ†ç»„å­˜å‚¨å®ä½“ï¼ˆä½¿ç”¨ entity_id å»é‡ï¼‰
        hop_entities: Dict[int, Dict[str, Dict]] = defaultdict(dict)

        # ä»åŸå§‹ clues ä¸­æå– final å®ä½“
        for clue in self.clues:
            # åªå…³æ³¨ Recall å’Œ Expand é˜¶æ®µçš„ final çº¿ç´¢
            stage = clue.get("stage")
            display_level = clue.get("display_level")

            if display_level != "final":
                continue

            if stage not in ["recall", "expand"]:
                continue

            # è·å– to èŠ‚ç‚¹ï¼ˆç›®æ ‡å®ä½“ï¼‰
            to_node = clue.get("to", {})
            if to_node.get("type") != "entity":
                continue

            entity_id = to_node.get("id")
            hop = to_node.get("hop", 0)

            if not entity_id:
                continue

            # å¦‚æœè¯¥ entity åœ¨å½“å‰ hop è¿˜æœªè®°å½•ï¼Œåˆ™æ·»åŠ 
            if entity_id not in hop_entities[hop]:
                hop_entities[hop][entity_id] = {
                    "id": entity_id,
                    "name": to_node.get("content", ""),
                    "type": to_node.get("category", ""),
                    "description": to_node.get("description", ""),
                    "hop": hop,
                    "stage": stage,
                    # ä¿ç•™å®Œæ•´çš„åŸå§‹æ•°æ®
                    **to_node
                }

        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²é”®çš„å­—å…¸
        result = {}
        for hop in sorted(hop_entities.keys()):
            result[str(hop)] = list(hop_entities[hop].values())

        # æ·»åŠ ç»Ÿè®¡æ—¥å¿—
        if result:
            stats_str = ", ".join([f"hop{h}={len(entities)}" for h, entities in result.items()])
            self.logger.info(f"ğŸ“Š å®ä½“æŒ‰è·³æ•°ç»Ÿè®¡ (ä» final çº¿ç´¢æå–): {stats_str}")
        else:
            self.logger.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½• final å®ä½“çº¿ç´¢")

        return result

    def _extract_min_lines_from_rerank(self, rerank_lines: Dict[str, List[List[Dict[str, Any]]]]) -> Dict[str, List[Dict[str, Any]]]:
        """
        ä» rerank_lines ä¸­æå–æ¯ä¸ªäº‹é¡¹çš„æœ€çŸ­è·¯å¾„

        Args:
            rerank_lines: {"event-id": [[path1], [path2], ...]}

        Returns:
            {"event-id": [{"query": ...}, {"entity": ...}, {"event": ...}]}
        """
        min_lines = {}

        for event_id, paths in rerank_lines.items():
            if not paths:
                continue

            # æ‰¾åˆ°æœ€çŸ­è·¯å¾„ï¼ˆä¼˜å…ˆæ¯”è¾ƒé•¿åº¦ï¼Œå…¶æ¬¡æ¯”è¾ƒç½®ä¿¡åº¦ï¼‰
            min_path = min(paths, key=lambda p: (len(p), -self._calculate_path_confidence(p)))
            min_lines[event_id] = min_path

        return min_lines

    def _extract_max_lines_from_rerank(self, rerank_lines: Dict[str, List[List[Dict[str, Any]]]]) -> Dict[str, List[Dict[str, Any]]]:
        """
        ä» rerank_lines ä¸­æå–æ¯ä¸ªäº‹é¡¹çš„æœ€é•¿è·¯å¾„

        Args:
            rerank_lines: {"event-id": [[path1], [path2], ...]}

        Returns:
            {"event-id": [{"query": ...}, {"entity": ...}, {"event": ...}]}
        """
        max_lines = {}

        for event_id, paths in rerank_lines.items():
            if not paths:
                continue

            # æ‰¾åˆ°æœ€é•¿è·¯å¾„ï¼ˆä¼˜å…ˆæ¯”è¾ƒé•¿åº¦ï¼Œå…¶æ¬¡æ¯”è¾ƒç½®ä¿¡åº¦ï¼‰
            max_path = max(paths, key=lambda p: (len(p), self._calculate_path_confidence(p)))
            max_lines[event_id] = max_path

        return max_lines

    def _calculate_path_confidence(self, path: List[Dict[str, Any]]) -> float:
        """
        è®¡ç®—è·¯å¾„çš„ç½®ä¿¡åº¦ï¼ˆç®€å•å–å¹³å‡ï¼Œæˆ–ä» metadata ä¸­è·å–ï¼‰

        Args:
            path: [{"query": ...}, {"entity": ...}, {"event": ...}]

        Returns:
            ç½®ä¿¡åº¦å€¼
        """
        # ä»è·¯å¾„èŠ‚ç‚¹çš„ metadata ä¸­æå–ç½®ä¿¡åº¦
        confidences = []
        for node in path:
            for node_type, node_data in node.items():
                if isinstance(node_data, dict):
                    conf = node_data.get("confidence", node_data.get("metadata", {}).get("confidence", 1.0))
                    if conf and conf > 0:
                        confidences.append(conf)

        # è¿”å›å¹³å‡ç½®ä¿¡åº¦ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›1.0
        return sum(confidences) / len(confidences) if confidences else 1.0

    def _build_event_lines_from_dict(self, event_paths: Dict[str, PathLine]) -> Dict[str, List[Dict[str, Any]]]:
        """
        ä»äº‹é¡¹è·¯å¾„å­—å…¸æ„å»ºå¯Œå«è·¯å¾„ä¿¡æ¯ï¼ˆå¯ç”¨äºæœ€çŸ­æˆ–æœ€é•¿è·¯å¾„ï¼‰

        Args:
            event_paths: {"event-id": PathLine}

        Returns:
            {
                "event-id": [
                    {"query": {...}},
                    {"entity": {...}},
                    {"entity": {...}},
                    {"event": {...}}
                ]
            }
        """
        result = {}

        for event_id, line in event_paths.items():
            path_items = []

            for node in line.nodes:
                # ä» self.nodes è·å–å®Œæ•´èŠ‚ç‚¹ä¿¡æ¯
                node_data = self.nodes.get(node.id, {})

                if node.type == "query":
                    path_items.append({
                        "query": {
                            "id": node.id,
                            "content": node.content,
                            "type": node_data.get("category", "origin"),
                            # ä¿ç•™å®Œæ•´æ•°æ®
                            **node_data
                        }
                    })
                elif node.type == "entity":
                    path_items.append({
                        "entity": {
                            "id": node.id,
                            "name": node.content,
                            "type": node_data.get("category", ""),
                            "description": node_data.get("description", ""),
                            "hop": node.hop,
                            "stage": node.stage,
                            # ä¿ç•™å®Œæ•´æ•°æ®
                            **node_data
                        }
                    })
                elif node.type == "event":
                    # è·å–å®Œæ•´çš„ event ä¿¡æ¯
                    path_items.append({
                        "event": {
                            "id": node.id,
                            "event_id": node_data.get("event_id", node.id),
                            "title": node.content,
                            "content": node_data.get("description", ""),
                            "category": node_data.get("category", ""),
                            "stage": node.stage,
                            # ä¿ç•™å®Œæ•´æ•°æ®
                            **node_data
                        }
                    })

            result[event_id] = path_items

        self.logger.info(f"ğŸ“‹ æ„å»ºäº‹é¡¹è·¯å¾„: {len(result)} ä¸ªäº‹é¡¹")

        return result

    def _build_all_event_lines(self, all_lines: List[PathLine]) -> Dict[str, List[List[Dict[str, Any]]]]:
        """
        ä»æ‰€æœ‰è·¯å¾„æ„å»ºå¯Œå«è·¯å¾„ä¿¡æ¯ï¼ˆæ¯ä¸ªäº‹é¡¹åŒ…å«æ‰€æœ‰è·¯å¾„ï¼‰

        Args:
            all_lines: æ‰€æœ‰è·¯å¾„åˆ—è¡¨

        Returns:
            {
                "event-id": [
                    [{"query": {...}}, {"entity": {...}}, {"event": {...}}],  # è·¯å¾„1
                    [{"query": {...}}, {"entity": {...}}, {"event": {...}}],  # è·¯å¾„2
                    ...
                ]
            }
        """
        from collections import defaultdict
        result = defaultdict(list)

        for line in all_lines:
            event_id = line.event_id
            path_items = []

            # ğŸ› è°ƒè¯•æ—¥å¿—ï¼šè¾“å‡ºè·¯å¾„ä¿¡æ¯
            entity_hops = [n.hop for n in line.nodes if n.type == "entity"]
            if entity_hops:
                self.logger.debug(
                    f"ğŸ›¤ï¸ Path for event {event_id[:20]}...: entity hops={entity_hops}"
                )

            for node in line.nodes:
                # ä» self.nodes è·å–å®Œæ•´èŠ‚ç‚¹ä¿¡æ¯
                node_data = self.nodes.get(node.id, {})

                if node.type == "query":
                    path_items.append({
                        "query": {
                            "id": node.id,
                            "content": node.content,
                            "type": node_data.get("category", "origin"),
                            # ä¿ç•™å®Œæ•´æ•°æ®
                            **node_data
                        }
                    })
                elif node.type == "entity":
                    path_items.append({
                        "entity": {
                            "id": node.id,
                            "name": node.content,
                            "type": node_data.get("category", ""),
                            "description": node_data.get("description", ""),
                            "hop": node.hop,
                            "stage": node.stage,
                            # ä¿ç•™å®Œæ•´æ•°æ®
                            **node_data
                        }
                    })
                elif node.type == "event":
                    # è·å–å®Œæ•´çš„ event ä¿¡æ¯
                    path_items.append({
                        "event": {
                            "id": node.id,
                            "event_id": node_data.get("event_id", node.id),
                            "title": node.content,
                            "content": node_data.get("description", ""),
                            "category": node_data.get("category", ""),
                            "stage": node.stage,
                            # ä¿ç•™å®Œæ•´æ•°æ®
                            **node_data
                        }
                    })

            # å°†è¿™æ¡è·¯å¾„æ·»åŠ åˆ°å¯¹åº”äº‹é¡¹çš„è·¯å¾„åˆ—è¡¨ä¸­
            result[event_id].append(path_items)

        # è½¬æ¢ä¸ºæ™®é€šå­—å…¸
        result_dict = dict(result)

        self.logger.info(
            f"ğŸ“‹ æ„å»ºäº‹é¡¹æ‰€æœ‰è·¯å¾„: {len(result_dict)} ä¸ªäº‹é¡¹, "
            f"å¹³å‡æ¯ä¸ªäº‹é¡¹ {sum(len(paths) for paths in result_dict.values()) / len(result_dict):.1f} æ¡è·¯å¾„"
        )

        return result_dict


def analyze_paths(
    clues: List[Dict[str, Any]],
    target_event_ids: Optional[List[str]] = None,
) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ†æçº¿ç´¢è·¯å¾„

    Args:
        clues: çº¿ç´¢åˆ—è¡¨
        target_event_ids: ç›®æ ‡äº‹é¡¹IDåˆ—è¡¨ï¼ˆä»…åˆ†æè¿™äº›äº‹é¡¹çš„è·¯å¾„ï¼‰
                         å¦‚æœä¸º Noneï¼Œåˆ™åˆ†ææ‰€æœ‰ final çº¿ç´¢

    Returns:
        è·¯å¾„åˆ†æç»“æœå­—å…¸
    """
    if not clues:
        return {
            "min_lines": {},
            "max_lines": {},
            "entitys": {},
            "rerank_lines": {},
            "stats": {
                "total_lines": 0,
                "avg_length": 0,
                "avg_confidence": 0,
            },
        }

    analyzer = PathAnalyzer(clues)
    result = analyzer.analyze(target_event_ids=target_event_ids)
    return result.to_dict()


__all__ = [
    "PathAnalyzer",
    "PathAnalysisResult",
    "PathLine",
    "PathNode",
    "analyze_paths",
]
