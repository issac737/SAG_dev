"""
DataFlow å¼•æ“æ ¸å¿ƒç±»

æä¾›æ ‡å‡†åŒ–çš„æ•°æ®å¤„ç†ä»»åŠ¡å¼•æ“
"""

import time
import uuid
from datetime import datetime
from typing import Any, Dict, List, Optional

from sqlalchemy import select

from dataflow.core.prompt.manager import get_prompt_manager
from dataflow.db import SourceChunk, SourceConfig, get_session_factory
from dataflow.engine.config import (
    ModelConfig,
    OutputConfig,
    TaskConfig,
)
from dataflow.engine.enums import LogLevel, TaskStage, TaskStatus
from dataflow.engine.models import StageResult, TaskLog, TaskResult
from dataflow.modules.extract.config import ExtractBaseConfig, ExtractConfig
from dataflow.modules.extract.extractor import EventExtractor
from dataflow.modules.load.config import (
    LoadBaseConfig, 
    DocumentLoadConfig, 
    ConversationLoadConfig,
    LoadResult
)
from dataflow.modules.load.loader import DocumentLoader, ConversationLoader
from dataflow.modules.search.config import SearchBaseConfig, SearchConfig
from dataflow.modules.search.searcher import EventSearcher
from dataflow.utils import get_logger, setup_logging

logger = get_logger("dataflow.engine")


class DataFlowEngine:
    """
    DataFlowä»»åŠ¡å¼•æ“

    æ”¯æŒä¸‰ä¸ªç‹¬ç«‹é˜¶æ®µï¼šLoadã€Extractã€Search
    å¯ä»¥å•ç‹¬æ‰§è¡Œï¼Œä¹Ÿå¯ä»¥é“¾å¼ç»„åˆ

    ä½¿ç”¨ç¤ºä¾‹ï¼š
        # æ–¹å¼1ï¼šç»Ÿä¸€é…ç½®
        >>> engine = DataFlowEngine(task_config=TaskConfig(...), model_config=ModelConfig(...))
        >>> result = engine.run()

        # æ–¹å¼2ï¼šç‹¬ç«‹æ‰§è¡Œå„é˜¶æ®µ
        >>> engine = DataFlowEngine(source_config_id="my-source")
        >>> engine.load(LoadBaseConfig(path="doc.md"))
        >>> engine.extract(ExtractBaseConfig(parallel=True))
        >>> engine.search(SearchBaseConfig(query="æŸ¥æ‰¾AIç›¸å…³å†…å®¹"))
        >>> result = engine.get_result()

        # æ–¹å¼3ï¼šé“¾å¼è°ƒç”¨
        >>> result = (
        ...     DataFlowEngine(source_config_id="my-source")
        ...     .load(LoadBaseConfig(path="doc.md"))
        ...     .extract(ExtractBaseConfig())
        ...     .search(SearchBaseConfig(query="..."))
        ...     .get_result()
        ... )
    """

    def __init__(
        self,
        task_config: Optional[TaskConfig] = None,
        model_config: Optional[ModelConfig] = None,
        source_config_id: Optional[str] = None,
        auto_setup_logging: bool = True,
    ):
        """
        åˆå§‹åŒ–å¼•æ“

        Args:
            task_config: ä»»åŠ¡é…ç½®ï¼ˆå¦‚æœæä¾›ï¼Œä½¿ç”¨ç»Ÿä¸€é…ç½®æ¨¡å¼ï¼‰
            model_config: ModelConfigé…ç½®ï¼ˆå¦‚æœä¸æä¾›ï¼Œä».envè¯»å–é»˜è®¤é…ç½®ï¼‰
            source_config_id: ä¿¡æ¯æºIDï¼ˆç®€åŒ–åˆå§‹åŒ–ï¼‰
            auto_setup_logging: æ˜¯å¦è‡ªåŠ¨è®¾ç½®æ—¥å¿—
        """
        if auto_setup_logging:
            setup_logging()

        # é…ç½®
        self.task_config = task_config

        # è½¬æ¢ model_config ä¸ºå­—å…¸ï¼ˆå¦‚æœæœ‰ï¼‰
        self.model_config_dict = model_config.model_dump() if model_config else None

        # ç”Ÿæˆä»»åŠ¡ID
        self.task_id = str(uuid.uuid4())

        # åˆå§‹åŒ–ç»„ä»¶
        self.prompt_manager = get_prompt_manager()
        self.session_factory = get_session_factory()

        self.document_loader = DocumentLoader()
        self.conversation_loader = ConversationLoader()
        self.extractor = EventExtractor(
            prompt_manager=self.prompt_manager,
            model_config=self.model_config_dict
        )
        self.searcher = EventSearcher(
            prompt_manager=self.prompt_manager,
            model_config=self.model_config_dict
        )

        # åˆå§‹åŒ–ç»“æœ
        task_name = task_config.task_name if task_config else "DataFlowä»»åŠ¡"
        self.result = TaskResult(
            task_id=self.task_id, task_name=task_name, status=TaskStatus.PENDING
        )

        # çŠ¶æ€ä¸Šä¸‹æ–‡
        self._source_config_id: Optional[str] = (
            source_config_id or (task_config.source_config_id if task_config else None)
        )
        self._load_result: Optional[LoadResult] = None  # Loadç»“æœ
        self._start_time: Optional[float] = None

        self._log(TaskStage.INIT, LogLevel.INFO, f"å¼•æ“åˆå§‹åŒ–å®Œæˆ: {self.task_id}")

    def _log(
        self,
        stage: TaskStage,
        level: LogLevel,
        message: str,
        extra: Optional[Dict[str, Any]] = None,
    ):
        """è®°å½•æ—¥å¿—"""
        log = TaskLog(stage=stage, level=level, message=message, extra=extra)
        self.result.logs.append(log)

        # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦æ‰“å°
        if not self.task_config or self.task_config.output.print_logs:
            log_func = getattr(logger, level.value)
            log_func(message, extra=extra)

    def _update_status(self, status: TaskStatus):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        self.result.status = status

    async def _ensure_source(self) -> str:
        """ç¡®ä¿ä¿¡æ¯æºå­˜åœ¨"""
        if not self._source_config_id:
            self._source_config_id = str(uuid.uuid4())
            self._log(TaskStage.INIT, LogLevel.INFO, f"è‡ªåŠ¨åˆ›å»ºä¿¡æ¯æº: {self._source_config_id}")

        async with self.session_factory() as session:
            result_db = await session.execute(
                select(SourceConfig).where(SourceConfig.id == self._source_config_id)
            )
            source = result_db.scalar_one_or_none()

            if not source:
                source_name = (
                    self.task_config.source_name
                    if self.task_config and self.task_config.source_name
                    else f"DataFlow-{uuid.uuid4().hex[:8]}"
                )
                source = SourceConfig(
                    id=self._source_config_id,
                    name=source_name,
                    description=f"ç”±DataFlowå¼•æ“åˆ›å»º (Task: {self.task_id})",
                    config={"task_id": self.task_id},
                )
                session.add(source)
                await session.commit()

        self.result.source_config_id = self._source_config_id
        return self._source_config_id

    def _apply_defaults(self, config):
        """
        åº”ç”¨ä»»åŠ¡çº§é»˜è®¤é…ç½®åˆ°é˜¶æ®µé…ç½®
        
        å¦‚æœé˜¶æ®µé…ç½®æœªè®¾ç½®ï¼Œåˆ™è‡ªåŠ¨ç»§æ‰¿ä»»åŠ¡é…ç½®çš„å€¼
        """
        if not self.task_config:
            return config
        
        # ç»§æ‰¿ background
        if hasattr(config, 'background') and not config.background:
            config.background = self.task_config.background
        
        # ç»§æ‰¿ source_config_id
        if hasattr(config, 'source_config_id') and not config.source_config_id:
            config.source_config_id = self.task_config.source_config_id
        
        return config

    # === Loadé˜¶æ®µ ===

    def load(self, config: LoadBaseConfig) -> "DataFlowEngine":
        """åŠ è½½æ–‡æ¡£ï¼ˆåŒæ­¥æ¥å£ï¼Œæ”¯æŒé“¾å¼è°ƒç”¨ï¼‰"""
        import asyncio

        asyncio.run(self.load_async(config))
        return self

    async def load_async(self, config):
        """
        åŠ è½½æ•°æ®ï¼ˆå¼‚æ­¥æ¥å£ï¼‰
        
        æ”¯æŒï¼š
        - DocumentLoadConfig: åŠ è½½æ–‡æ¡£ï¼ˆæ–‡ä»¶æˆ–æ•°æ®åº“ï¼‰
        - ConversationLoadConfig: åŠ è½½ä¼šè¯ï¼ˆæ•°æ®åº“ï¼‰
        """
        stage_start = time.time()
        self._update_status(TaskStatus.LOADING)
        self._log(TaskStage.LOAD, LogLevel.INFO, "å¼€å§‹åŠ è½½æ•°æ®")

        try:
            source_config_id = await self._ensure_source()

            # åº”ç”¨ä»»åŠ¡çº§é»˜è®¤é…ç½®
            config.source_config_id = config.source_config_id or source_config_id
            self._apply_defaults(config)

            # æ ¹æ®é…ç½®ç±»å‹é€‰æ‹©loader
            if isinstance(config, ConversationLoadConfig):
                load_result = await self.conversation_loader.load(config)
            elif isinstance(config, DocumentLoadConfig):
                load_result = await self.document_loader.load(config)
            else:
                raise ValueError(
                    f"ä¸æ”¯æŒçš„é…ç½®ç±»å‹: {type(config).__name__}ã€‚"
                    f"è¯·ä½¿ç”¨DocumentLoadConfigæˆ–ConversationLoadConfig"
                )

            # ä¿å­˜LoadResultåˆ°ä¸Šä¸‹æ–‡
            self._load_result = load_result

            # ä¿å­˜ç»“æœåˆ°TaskResult
            self.result.load_result = StageResult(
                stage=TaskStage.LOAD,
                status="success",
                data_ids=load_result.chunk_ids,
                data_full=[],  # ä¸ä¿å­˜å®Œæ•´æ•°æ®ï¼Œé¿å…è¿‡å¤§
                stats={
                    "source_id": load_result.source_id,
                    "source_type": load_result.source_type,
                    "chunk_count": load_result.chunk_count,
                    "title": load_result.title,
                    **load_result.extra
                },
                duration=time.time() - stage_start,
            )

            self._log(
                TaskStage.LOAD, 
                LogLevel.INFO, 
                f"åŠ è½½å®Œæˆ: {load_result.source_type} "
                f"source_id={load_result.source_id}, "
                f"chunks={load_result.chunk_count}"
            )

        except Exception as e:
            self.result.load_result = StageResult(
                stage=TaskStage.LOAD,
                status="failed",
                error=str(e),
                duration=time.time() - stage_start,
            )
            self._log(TaskStage.LOAD, LogLevel.ERROR, f"åŠ è½½å¤±è´¥: {e}")
            if self.task_config and self.task_config.fail_fast:
                raise

    # === Extracté˜¶æ®µ ===

    def extract(self, config: Optional[ExtractBaseConfig] = None) -> "DataFlowEngine":
        """æå–äº‹é¡¹ï¼ˆåŒæ­¥æ¥å£ï¼Œæ”¯æŒé“¾å¼è°ƒç”¨ï¼‰"""
        import asyncio

        asyncio.run(self.extract_async(config))
        return self

    async def extract_async(self, config: Optional[ExtractBaseConfig] = None):
        """
        æå–äº‹é¡¹ï¼ˆå¼‚æ­¥æ¥å£ï¼‰
        
        å‰æï¼šå¿…é¡»å…ˆæ‰§è¡ŒLoadé˜¶æ®µ
        """
        # éªŒè¯å‰ç½®æ¡ä»¶
        if not self._load_result:
            self._log(
                TaskStage.EXTRACT, 
                LogLevel.WARNING, 
                "æœªåŠ è½½æ•°æ®ï¼Œè·³è¿‡æå–é˜¶æ®µ"
            )
            return

        if not self._load_result.chunk_ids:
            self._log(
                TaskStage.EXTRACT, 
                LogLevel.WARNING, 
                "Loadé˜¶æ®µæ²¡æœ‰ç”Ÿæˆchunksï¼Œè·³è¿‡æå–é˜¶æ®µ"
            )
            return

        stage_start = time.time()
        self._update_status(TaskStatus.EXTRACTING)
        self._log(TaskStage.EXTRACT, LogLevel.INFO, "å¼€å§‹æå–äº‹é¡¹")

        try:
            source_config_id = await self._ensure_source()
            config = config or ExtractBaseConfig()
            
            # åº”ç”¨ä»»åŠ¡çº§é»˜è®¤é…ç½®
            self._apply_defaults(config)

            # ç»„è£…å®Œæ•´é…ç½®ï¼šä½¿ç”¨Loadç»“æœçš„chunk_ids
            extract_config = ExtractConfig(
                source_config_id=source_config_id,
                chunk_ids=self._load_result.chunk_ids,
                **config.model_dump()
            )

            events = await self.extractor.extract(extract_config)

            # ä¿å­˜ç»“æœ
            self.result.extract_result = StageResult(
                stage=TaskStage.EXTRACT,
                status="success",
                data_ids=[e.id for e in events],
                data_full=[
                    {
                        "id": e.id,
                        "title": e.title,
                        "summary": e.summary,
                        "content": e.content,
                        "entities": [
                            {"name": a.entity.name, "type": a.entity.type}
                            for a in e.event_associations
                        ],
                    }
                    for e in events
                ],
                stats={
                    "event_count": len(events),
                    "chunk_count": len(self._load_result.chunk_ids),
                    "events_per_chunk": round(
                        len(events) / len(self._load_result.chunk_ids), 2
                    ) if self._load_result.chunk_ids else 0
                },
                duration=time.time() - stage_start,
            )

            self._log(
                TaskStage.EXTRACT, 
                LogLevel.INFO, 
                f"æå–å®Œæˆ: {len(events)} ä¸ªäº‹é¡¹"
            )

        except Exception as e:
            self.result.extract_result = StageResult(
                stage=TaskStage.EXTRACT,
                status="failed",
                error=str(e),
                duration=time.time() - stage_start,
            )
            self._log(TaskStage.EXTRACT, LogLevel.ERROR, f"æå–å¤±è´¥: {e}")
            if self.task_config and self.task_config.fail_fast:
                raise

    # === Searché˜¶æ®µ ===

    def search(self, config: SearchBaseConfig) -> "DataFlowEngine":
        """æœç´¢äº‹é¡¹ï¼ˆåŒæ­¥æ¥å£ï¼Œæ”¯æŒé“¾å¼è°ƒç”¨ï¼‰"""
        import asyncio

        asyncio.run(self.search_async(config))
        return self

    async def search_async(self, config: SearchBaseConfig):
        """æœç´¢äº‹é¡¹ï¼ˆå¼‚æ­¥æ¥å£ï¼‰"""
        if not config.query:
            self._log(TaskStage.SEARCH, LogLevel.WARNING, "æœªæä¾›æ£€ç´¢ç›®æ ‡ï¼Œè·³è¿‡æœç´¢é˜¶æ®µ")
            return

        stage_start = time.time()
        self._update_status(TaskStatus.SEARCHING)
        self._log(TaskStage.SEARCH, LogLevel.INFO, f"å¼€å§‹æœç´¢: {config.query}")

        try:
            # åº”ç”¨ä»»åŠ¡çº§é»˜è®¤é…ç½®
            self._apply_defaults(config)
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯å®Œæ•´çš„ SearchConfig
            if isinstance(config, SearchConfig):
                search_config = config
            else:
                # éœ€è¦ç»„è£…å®Œæ•´é…ç½®
                source_config_id = await self._ensure_source()
                search_config = SearchConfig(
                    source_config_id=source_config_id,
                    article_id=None,
                    **config.model_dump()
                )

            # æœç´¢è¿”å›å­—å…¸æ ¼å¼: {"events": [...], "clues": [...], "lines": {...}, "entitys": {...}, "rerank_lines": {...}, "stats": {...}, "query": {...}}
            # æ³¨æ„ï¼šclues ç°åœ¨æ˜¯ from-to æ ¼å¼çš„è¯¦ç»†çº¿ç´¢åˆ—è¡¨
            search_result = await self.searcher.search(search_config)
            matched_events = search_result.get("events", [])
            search_clues = search_result.get("clues", [])  # âœ… æ”¹ä¸ºåˆ—è¡¨æ ¼å¼

            # ä¿å­˜ç»“æœ
            self.result.search_result = StageResult(
                stage=TaskStage.SEARCH,
                status="success",
                data_ids=[e.id for e in matched_events],
                data_full=[
                    {
                        "id": e.id,
                        "title": e.title,
                        "summary": e.summary,
                        "content": e.content,
                    }
                    for e in matched_events
                ],
                stats={
                    "matched_count": len(matched_events),
                    "clues": search_clues,  # ä¿å­˜cluesåˆ°statsä¸­
                    # ğŸ†• ä¿å­˜å®Œæ•´çš„æœç´¢ç»“æœï¼ˆåŒ…å«è·¯å¾„åˆ†ææ•°æ®ï¼‰
                    "min_lines": search_result.get("min_lines", {}),
                    "max_lines": search_result.get("max_lines", {}),
                    "entitys": search_result.get("entitys", {}),
                    "rerank_lines": search_result.get("rerank_lines", {}),
                    "search_stats": search_result.get("stats", {}),
                    "query_info": search_result.get("query", {}),
                },
                duration=time.time() - stage_start,
            )

            self._log(
                TaskStage.SEARCH, LogLevel.INFO, f"æœç´¢å®Œæˆ: {len(matched_events)} ä¸ªåŒ¹é…äº‹é¡¹"
            )

        except Exception as e:
            self.result.search_result = StageResult(
                stage=TaskStage.SEARCH,
                status="failed",
                error=str(e),
                duration=time.time() - stage_start,
            )
            self._log(TaskStage.SEARCH, LogLevel.ERROR, f"æœç´¢å¤±è´¥: {e}")
            if self.task_config and self.task_config.fail_fast:
                raise

    # === ç»Ÿä¸€æ‰§è¡Œ ===

    def run(self) -> TaskResult:
        """è¿è¡Œä»»åŠ¡ï¼ˆæ ¹æ®é…ç½®æ‰§è¡Œç›¸åº”é˜¶æ®µï¼‰"""
        import asyncio

        return asyncio.run(self.run_async())

    async def run_async(self) -> TaskResult:
        """è¿è¡Œä»»åŠ¡ï¼ˆå¼‚æ­¥ï¼‰"""
        self._start_time = time.time()
        self.result.start_time = datetime.utcnow()

        try:
            if not self.task_config:
                raise ValueError("æœªæä¾›task_configï¼Œè¯·ä½¿ç”¨ç‹¬ç«‹çš„load/extract/searchæ–¹æ³•")

            # æ‰§è¡Œå¯ç”¨çš„é˜¶æ®µ
            if self.task_config.load:
                await self.load_async(self.task_config.load)

            if self.task_config.extract:
                await self.extract_async(self.task_config.extract)

            if self.task_config.search:
                await self.search_async(self.task_config.search)

            self._update_status(TaskStatus.COMPLETED)
            self._log(TaskStage.OUTPUT, LogLevel.INFO, "ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ")

        except Exception as e:
            self._update_status(TaskStatus.FAILED)
            self.result.error = str(e)
            self._log(TaskStage.OUTPUT, LogLevel.ERROR, f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")

        finally:
            self.result.end_time = datetime.utcnow()
            self.result.duration = time.time() - self._start_time
            self._compute_stats()

        return self.result

    # ============ ä¾¿æ·å±æ€§ ============
    
    @property
    def chunk_ids(self) -> Optional[List[str]]:
        """è·å–å½“å‰chunk_ids"""
        return self._load_result.chunk_ids if self._load_result else None
    
    @property
    def source_id(self) -> Optional[str]:
        """è·å–å½“å‰source_idï¼ˆarticle_idæˆ–conversation_idï¼‰"""
        return self._load_result.source_id if self._load_result else None
    
    @property
    def source_type(self) -> Optional[str]:
        """è·å–å½“å‰source_typeï¼ˆARTICLEæˆ–CONVERSATIONï¼‰"""
        return self._load_result.source_type if self._load_result else None
    
    # ============ å·¥å…·æ–¹æ³• ============
    
    def _compute_stats(self):
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        if self.result.load_result:
            stats["chunks"] = len(self.result.load_result.data_ids)
        if self.result.extract_result:
            stats["events"] = len(self.result.extract_result.data_ids)
        if self.result.search_result:
            stats["matched_events"] = len(self.result.search_result.data_ids)
        stats["log_count"] = len(self.result.logs)
        self.result.stats = stats

    def get_result(self) -> TaskResult:
        """è·å–ç»“æœ"""
        return self.result

    def output(self, output_config: Optional[OutputConfig] = None) -> Optional[str]:
        """è¾“å‡ºç»“æœ"""
        config = output_config or (
            self.task_config.output if self.task_config else OutputConfig()
        )
        if config.format == "json":
            content = self.result.to_json(config)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {config.format}")

        if config.export_path:
            config.export_path.write_text(content, encoding="utf-8")
            logger.info(f"ç»“æœå·²å¯¼å‡ºåˆ°: {config.export_path}")
            return None
        return content

