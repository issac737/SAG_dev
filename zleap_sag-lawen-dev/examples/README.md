# DataFlow å¼•æ“ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

DataFlow å¼•æ“æ˜¯ä¸€ä¸ªæ ‡å‡†åŒ–çš„æ•°æ®å¤„ç†ä»»åŠ¡å¼•æ“ï¼Œæ”¯æŒä¸‰ä¸ªç‹¬ç«‹çš„å¤„ç†é˜¶æ®µï¼š

1. **Loadï¼ˆåŠ è½½ï¼‰** - åŠ è½½å’Œè§£ææ–‡æ¡£
2. **Extractï¼ˆæå–ï¼‰** - ä»æ–‡æ¡£ä¸­æå–äº‹é¡¹å’Œå®ä½“
3. **Searchï¼ˆæœç´¢ï¼‰** - æ”¯æŒå¤šç§æœç´¢æ¨¡å¼ï¼š
   - **LLM** - å¤§æ¨¡å‹æ™ºèƒ½æ£€ç´¢ï¼ˆé»˜è®¤ï¼‰
   - **RAG** - çº¯å‘é‡æ£€ç´¢ï¼ˆå¼€å‘ä¸­ï¼‰
   - **SAG** - SQLé©±åŠ¨çš„æ··åˆæ£€ç´¢ï¼ˆå¼€å‘ä¸­ï¼‰

## æ ¸å¿ƒç‰¹æ€§

âœ… **å¯åˆ†å¯åˆ** - ä¸‰ä¸ªé˜¶æ®µå®Œå…¨ç‹¬ç«‹ï¼Œå¯å•ç‹¬æ‰§è¡Œæˆ–ç»„åˆ  
âœ… **çµæ´»è¾“å‡º** - æ”¯æŒIDæˆ–å®Œæ•´å†…å®¹ä¸¤ç§è¾“å‡ºæ¨¡å¼  
âœ… **æ—¥å¿—ç®¡ç†** - æ—¥å¿—æ€»æ˜¯ä¿å­˜ï¼Œå¯é…ç½®æ˜¯å¦æ‰“å°  
âœ… **é“¾å¼è°ƒç”¨** - æ”¯æŒä¼˜é›…çš„é“¾å¼API  
âœ… **ç»Ÿä¸€é…ç½®** - ä¹Ÿæ”¯æŒç»Ÿä¸€çš„TaskConfigé…ç½®  
âœ… **å¼‚æ­¥æ”¯æŒ** - æ”¯æŒå¼‚æ­¥å’ŒåŒæ­¥ä¸¤ç§æ‰§è¡Œæ–¹å¼

## å¿«é€Ÿå¼€å§‹

### 1. åŸºç¡€ä½¿ç”¨ï¼ˆåˆ†æ­¥è°ƒç”¨ï¼‰

```python
from dataflow import DataFlowEngine, LoadBaseConfig, ExtractBaseConfig

# åˆå§‹åŒ–å¼•æ“
engine = DataFlowEngine(source_config_id="my-source")

# åŠ è½½æ–‡æ¡£
engine.load(LoadBaseConfig(path="docs/document.md"))

# æå–äº‹é¡¹
engine.extract(ExtractBaseConfig(parallel=True))

# è·å–ç»“æœ
result = engine.get_result()
print(f"æå–äº† {len(result.extract_result.data_ids)} ä¸ªäº‹é¡¹")
```

### 2. é“¾å¼è°ƒç”¨ï¼ˆæ¨èï¼‰

```python
from dataflow import DataFlowEngine, LoadBaseConfig, ExtractBaseConfig, SearchBaseConfig

result = (
    DataFlowEngine(source_config_id="my-source")
    .load(LoadBaseConfig(path="docs/document.md"))
    .extract(ExtractBaseConfig(parallel=True, max_concurrency=3))
    .search(SearchBaseConfig(query="æŸ¥æ‰¾AIç›¸å…³å†…å®¹", top_k=5))
    .get_result()
)

print(f"åŒ¹é…äº† {len(result.search_result.data_ids)} ä¸ªäº‹é¡¹")
```

### 3. ç»Ÿä¸€é…ç½®ï¼ˆé…ç½®å¯åˆ†å¯åˆï¼‰

```python
from dataflow import DataFlowEngine, TaskConfig, LoadBaseConfig, ExtractBaseConfig, OutputConfig, OutputMode

task_config = TaskConfig(
    task_name="å®Œæ•´æµç¨‹",
    source_config_id="my-source",
    background="è¿™æ˜¯æŠ€æœ¯æ–‡æ¡£é›†åˆï¼Œé‡ç‚¹å…³æ³¨æŠ€æœ¯å®ç°",  # å…¨å±€èƒŒæ™¯ä¿¡æ¯
    load=LoadBaseConfig(path="docs/document.md"),
    extract=ExtractBaseConfig(parallel=True),  # ä½¿ç”¨å…¨å±€ background
    output=OutputConfig(mode=OutputMode.ID_ONLY),
)

engine = DataFlowEngine(task_config=task_config)
result = engine.run()

# è¾“å‡ºç»“æœ
output = engine.output()
print(output)
```

## é…ç½®è¯´æ˜

### ModelConfig - LLMé…ç½®

```python
from dataflow import ModelConfig

model_config = ModelConfig(
    api_key="sk-your-api-key",  # APIå¯†é’¥ï¼ˆç•™ç©ºä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
    model="sophnet/Qwen3-30B-A3B-Thinking-2507",  # æ¨¡å‹åç§°
    base_url="https://api.openai.com/v1",  # APIåŸºç¡€URLï¼ˆä¸­è½¬APIï¼‰
    timeout=60,  # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    max_retries=3,  # æœ€å¤§é‡è¯•æ¬¡æ•°
    temperature=0.3,  # ç”Ÿæˆæ¸©åº¦
    with_retry=True,  # æ˜¯å¦å¯ç”¨é‡è¯•
)
```

### LoadBaseConfig - åŠ è½½é˜¶æ®µé…ç½®

```python
from dataflow import LoadBaseConfig

load_config = LoadBaseConfig(
    path="docs/document.md",  # æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„ï¼ˆå¿…å¡«ï¼‰
    auto_vector=True,  # æ˜¯å¦è‡ªåŠ¨ç´¢å¼•åˆ°ES
    recursive=True,  # æ˜¯å¦é€’å½’æœç´¢å­ç›®å½•
    pattern="*.md",  # æ–‡ä»¶åŒ¹é…æ¨¡å¼
    max_tokens=8000,  # æœ€å¤§tokenæ•°
)
# æ³¨æ„ï¼šbackground, source_config_id ç”±å¼•æ“è‡ªåŠ¨æä¾›
```

### ExtractBaseConfig - æå–é˜¶æ®µé…ç½®

```python
from dataflow import ExtractBaseConfig

extract_config = ExtractBaseConfig(
    parallel=True,  # æ˜¯å¦å¹¶è¡Œå¤„ç†
    max_concurrency=3,  # æœ€å¤§å¹¶å‘æ•°
    max_sections=10,  # æ¯æ‰¹æœ€å¤§ç‰‡æ®µæ•°
    max_tokens=8000,  # æ¯æ‰¹æœ€å¤§tokenæ•°
)
# æ³¨æ„ï¼šbackground, source_config_id, article_id ç”±å¼•æ“è‡ªåŠ¨æä¾›
```

### SearchBaseConfig - æœç´¢é˜¶æ®µé…ç½®

```python
from dataflow import SearchBaseConfig, SearchMode

search_config = SearchBaseConfig(
    query="æŸ¥æ‰¾AIç›¸å…³å†…å®¹",  # æ£€ç´¢ç›®æ ‡ï¼ˆå¿…å¡«ï¼‰
    mode=SearchMode.LLM,  # æœç´¢æ¨¡å¼ï¼ˆé»˜è®¤LLMï¼‰
    threshold=0.5,  # ç›¸å…³åº¦é˜ˆå€¼
    top_k=10,  # è¿”å›æ•°é‡ä¸Šé™
)
# æ³¨æ„ï¼šbackground, source_config_id, article_id ç”±å¼•æ“è‡ªåŠ¨æä¾›

# ä¸‰ç§æœç´¢æ¨¡å¼ï¼š
# - SearchMode.LLM: å¤§æ¨¡å‹æ™ºèƒ½æ£€ç´¢ï¼ˆé»˜è®¤ï¼‰
# - SearchMode.RAG: çº¯å‘é‡æ£€ç´¢ï¼ˆå¼€å‘ä¸­ï¼‰
# - SearchMode.SAG: SQLé©±åŠ¨çš„æ··åˆæ£€ç´¢ï¼ˆå¼€å‘ä¸­ï¼‰
```

### OutputConfig - è¾“å‡ºé…ç½®

```python
from dataflow import OutputConfig, OutputMode

output_config = OutputConfig(
    mode=OutputMode.FULL,  # è¾“å‡ºæ¨¡å¼ï¼ˆID_ONLY æˆ– FULLï¼‰
    format="json",  # è¾“å‡ºæ ¼å¼ï¼ˆjson/markdownï¼‰
    include_logs=True,  # æ˜¯å¦åœ¨è¾“å‡ºä¸­åŒ…å«æ—¥å¿—
    print_logs=True,  # æ˜¯å¦æ‰“å°æ—¥å¿—åˆ°æ§åˆ¶å°
    export_path=None,  # å¯¼å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆç•™ç©ºè¿”å›å­—ç¬¦ä¸²ï¼‰
    pretty=True,  # æ˜¯å¦ç¾åŒ–è¾“å‡º
)
```

## ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šåªåŠ è½½æ–‡æ¡£

```python
engine = DataFlowEngine(source_config_id="my-source")
engine.load(LoadBaseConfig(path="docs/document.md"))

result = engine.get_result()
sections_ids = result.load_result.data_ids  # è·å–ç‰‡æ®µIDåˆ—è¡¨
```

### åœºæ™¯2ï¼šåªæå–äº‹é¡¹

```python
engine = DataFlowEngine(source_config_id="my-source")
engine._article_id = "existing-article-id"  # è®¾ç½®å·²å­˜åœ¨çš„æ–‡ç« ID
engine.extract(ExtractBaseConfig(parallel=True))

result = engine.get_result()
events = result.extract_result.data_full  # è·å–å®Œæ•´äº‹é¡¹åˆ—è¡¨
```

### åœºæ™¯3ï¼šåªæœç´¢äº‹é¡¹

```python
engine = DataFlowEngine(source_config_id="my-source")
engine.search(SearchBaseConfig(query="æŸ¥æ‰¾AIç›¸å…³å†…å®¹"))

result = engine.get_result()
matched_ids = result.search_result.data_ids  # è·å–åŒ¹é…äº‹é¡¹ID
```

### åœºæ™¯4ï¼šå®Œæ•´æµç¨‹

```python
task_config = TaskConfig(
    task_name="å®Œæ•´æµç¨‹",
    source_config_id="my-source",
    background="æŠ€æœ¯æ–‡æ¡£ï¼Œå…³æ³¨AIæŠ€æœ¯å®ç°",  # å…¨å±€èƒŒæ™¯ä¿¡æ¯
    load=LoadBaseConfig(path="docs/document.md"),
    extract=ExtractBaseConfig(parallel=True),
    search=SearchBaseConfig(query="æŸ¥æ‰¾..."),
)

engine = DataFlowEngine(task_config=task_config)
result = engine.run()
```

### åœºæ™¯5ï¼šæ‰¹é‡å¤„ç†

```python
documents = [
    ("docs/doc1.md", "æŠ€æœ¯æ–‡æ¡£1"),
    ("docs/doc2.md", "æŠ€æœ¯æ–‡æ¡£2"),
    ("docs/doc3.md", "æŠ€æœ¯æ–‡æ¡£3"),
]

for path, background in documents:
    result = (
        DataFlowEngine(source_config_id="batch-source")
        .load(LoadBaseConfig(path=path))  # background é€šè¿‡ TaskConfig å…¨å±€é…ç½®
        .extract(ExtractBaseConfig(parallel=True))
        .get_result()
    )
    print(f"{path}: {result.stats.get('events', 0)} ä¸ªäº‹é¡¹")
```

## è¾“å‡ºæ¨¡å¼

### ID_ONLY æ¨¡å¼

åªè¾“å‡ºæ•°æ®IDï¼Œé€‚åˆï¼š
- éœ€è¦è¿›ä¸€æ­¥å¤„ç†çš„åœºæ™¯
- æ•°æ®é‡å¤§çš„åœºæ™¯
- åªéœ€è¦æ ‡è¯†ç¬¦çš„åœºæ™¯

```python
OutputConfig(mode=OutputMode.ID_ONLY)

# è¾“å‡ºç¤ºä¾‹
{
  "load": {
    "results": ["section-id-1", "section-id-2", ...]
  },
  "extract": {
    "results": ["event-id-1", "event-id-2", ...]
  }
}
```

### FULL æ¨¡å¼

è¾“å‡ºå®Œæ•´æ•°æ®ï¼Œé€‚åˆï¼š
- æœ€ç»ˆç»“æœå±•ç¤º
- éœ€è¦è¯¦ç»†ä¿¡æ¯çš„åœºæ™¯
- ä¸€æ¬¡æ€§è·å–æ‰€æœ‰æ•°æ®

```python
OutputConfig(mode=OutputMode.FULL)

# è¾“å‡ºç¤ºä¾‹
{
  "load": {
    "results": [
      {"id": "...", "heading": "...", "content": "..."},
      ...
    ]
  },
  "extract": {
    "results": [
      {"id": "...", "title": "...", "content": "...", "entities": [...]},
      ...
    ]
  }
}
```

## æ—¥å¿—ç®¡ç†

æ—¥å¿—æ€»æ˜¯ä¼šä¿å­˜åœ¨ `TaskResult.logs` ä¸­ï¼Œä½†å¯ä»¥é€šè¿‡é…ç½®æ§åˆ¶æ˜¯å¦æ‰“å°ï¼š

```python
# ä¸æ‰“å°æ—¥å¿—ä½†ä¿å­˜
OutputConfig(print_logs=False, include_logs=True)

# æ‰“å°æ—¥å¿—ä¸”ä¿å­˜
OutputConfig(print_logs=True, include_logs=True)

# æ‰“å°æ—¥å¿—ä½†ä¸åœ¨è¾“å‡ºä¸­åŒ…å«
OutputConfig(print_logs=True, include_logs=False)
```

æŸ¥çœ‹æ—¥å¿—ï¼š

```python
result = engine.get_result()

# æŸ¥çœ‹æ‰€æœ‰æ—¥å¿—
for log in result.logs:
    print(log)

# åªæŸ¥çœ‹é”™è¯¯æ—¥å¿—
for log in result.logs:
    if log.level.value == "error":
        print(log)
```

## å¼‚æ­¥æ‰§è¡Œ

```python
import asyncio

async def async_task():
    engine = DataFlowEngine(source_config_id="my-source")

    # å¼‚æ­¥åŠ è½½
    await engine.load_async(LoadBaseConfig(path="docs/document.md"))

    # å¼‚æ­¥æå–
    await engine.extract_async(ExtractBaseConfig(parallel=True))

    return engine.get_result()

result = asyncio.run(async_task())
```

## é”™è¯¯å¤„ç†

### å¿«é€Ÿå¤±è´¥æ¨¡å¼

```python
task_config = TaskConfig(
    fail_fast=True,  # é‡åˆ°é”™è¯¯ç«‹å³åœæ­¢
    ...
)
```

### å®¹é”™æ¨¡å¼

```python
task_config = TaskConfig(
    fail_fast=False,  # å³ä½¿æŸä¸ªé˜¶æ®µå¤±è´¥ä¹Ÿç»§ç»­æ‰§è¡Œ
    ...
)

result = engine.run()

# æ£€æŸ¥æ¯ä¸ªé˜¶æ®µçš„çŠ¶æ€
if result.load_result and result.load_result.status == "failed":
    print(f"åŠ è½½å¤±è´¥: {result.load_result.error}")

if result.extract_result and result.extract_result.status == "failed":
    print(f"æå–å¤±è´¥: {result.extract_result.error}")
```

## æœ€ä½³å®è·µ

1. **æ¨èä½¿ç”¨é“¾å¼è°ƒç”¨** - ä»£ç æ›´ç®€æ´ï¼Œé€»è¾‘æ›´æ¸…æ™°
2. **å¤§æ–‡æ¡£å¯ç”¨å¹¶è¡Œå¤„ç†** - æé«˜å¤„ç†æ•ˆç‡
3. **æä¾›èƒŒæ™¯ä¿¡æ¯** - æé«˜AIæå–å‡†ç¡®æ€§
4. **åˆç†è®¾ç½®æ‰¹æ¬¡å¤§å°** - é¿å…è¶…å‡ºtokené™åˆ¶
5. **ä½¿ç”¨IDæ¨¡å¼å¤„ç†å¤§æ•°æ®** - å‡å°‘å†…å­˜å ç”¨
6. **ä¿å­˜æ—¥å¿—ä¾¿äºè°ƒè¯•** - include_logs=True
7. **ä½¿ç”¨ä¸­è½¬APIæé«˜ç¨³å®šæ€§** - é…ç½® base_url
8. **å¼‚æ­¥æ‰§è¡Œæ‰¹é‡ä»»åŠ¡** - æé«˜å¹¶å‘æ•ˆç‡

## å¹¶å‘å®‰å…¨æ€§ âš¡

DataFlow å¼•æ“**å®Œå…¨æ”¯æŒå¹¶å‘è¿è¡Œ**ï¼Œä½ å¯ä»¥å®‰å…¨åœ°åˆ›å»ºå¤šä¸ªå¼•æ“å®ä¾‹ï¼Œæ¯ä¸ªå®ä¾‹ä½¿ç”¨ç‹¬ç«‹çš„é…ç½®ï¼š

### âœ… å¹¶å‘åœºæ™¯ç¤ºä¾‹

```python
import asyncio

async def run_multiple_engines():
    # å¼•æ“1ï¼šå¤„ç†æŠ€æœ¯æ–‡æ¡£
    engine1 = DataFlowEngine(
        model_config=ModelConfig(api_key="sk-tech", model="sophnet/Qwen3-30B-A3B-Thinking-2507", temperature=0.2),
        source_config_id="tech-docs"
    )

    # å¼•æ“2ï¼šå¤„ç†è¥é”€å†…å®¹
    engine2 = DataFlowEngine(
        model_config=ModelConfig(api_key="sk-marketing", model="gpt-3.5-turbo", temperature=0.7),
        source_config_id="marketing"
    )
    
    # å¹¶å‘è¿è¡Œ - é…ç½®å®Œå…¨éš”ç¦»ï¼
    result1, result2 = await asyncio.gather(
        engine1.load_async(LoadStageConfig(path="docs/tech.md")),
        engine2.load_async(LoadStageConfig(path="docs/marketing.md"))
    )
```

### ğŸ”’ çº¿ç¨‹å®‰å…¨ä¿è¯

- âœ… **ä¸ä¿®æ”¹å…¨å±€çŠ¶æ€** - æ¯ä¸ªå¼•æ“ç‹¬ç«‹é…ç½®
- âœ… **çº¿ç¨‹å®‰å…¨** - æ”¯æŒå¤šçº¿ç¨‹å¹¶å‘
- âœ… **è¿›ç¨‹å®‰å…¨** - æ”¯æŒå¤šè¿›ç¨‹éƒ¨ç½²
- âœ… **æ— ç«æ€æ¡ä»¶** - é…ç½®éš”ç¦»ï¼Œäº’ä¸å¹²æ‰°

### ğŸ“Š æ€§èƒ½ç‰¹æ€§

- æ”¯æŒå¤§è§„æ¨¡å¹¶å‘ï¼ˆ100+ å¼•æ“å®ä¾‹ï¼‰
- æ¯ä¸ªå¼•æ“åˆ›å»ºæ—¶é—´ < 10ms
- å†…å­˜å ç”¨åˆç†
- æ— å…¨å±€é”ç«äº‰

### ğŸ¯ å…¸å‹åº”ç”¨åœºæ™¯

1. **å¤šç§Ÿæˆ·SaaS** - æ¯ä¸ªç§Ÿæˆ·ç‹¬ç«‹é…ç½®
2. **è´Ÿè½½å‡è¡¡** - åˆ†æ•£åˆ°å¤šä¸ªAPIç«¯ç‚¹
3. **æ‰¹é‡å¤„ç†** - å¹¶è¡Œå¤„ç†å¤šä¸ªæ–‡æ¡£
4. **A/Bæµ‹è¯•** - åŒæ—¶æµ‹è¯•ä¸åŒæ¨¡å‹é…ç½®

æŸ¥çœ‹ `concurrent_engines_demo.py` è·å–å®Œæ•´çš„å¹¶å‘ç¤ºä¾‹ã€‚

## å®Œæ•´ç¤ºä¾‹

- `engine_example.py` - åŸºç¡€åŠŸèƒ½ç¤ºä¾‹
- `concurrent_engines_demo.py` - å¹¶å‘å®‰å…¨æ¼”ç¤º
- `search_modes_demo.py` - æœç´¢æ¨¡å¼æ¼”ç¤ºï¼ˆLLM/RAG/SAGï¼‰

## æ³¨æ„äº‹é¡¹

1. è¿è¡Œå‰è¯·ç¡®ä¿å·²é…ç½® LLM_API_KEY ç¯å¢ƒå˜é‡
2. éœ€è¦å…ˆåˆå§‹åŒ–æ•°æ®åº“ï¼ˆè¿è¡Œ `scripts/init_database.py`ï¼‰
3. Loadé˜¶æ®µä¾èµ–å®é™…çš„æ–‡æ¡£æ–‡ä»¶
4. Extracté˜¶æ®µä¾èµ–Loadé˜¶æ®µçš„è¾“å‡º
5. Searché˜¶æ®µä¾èµ–æ•°æ®åº“ä¸­å·²æœ‰çš„äº‹é¡¹æ•°æ®

## æ•…éšœæ’æŸ¥

### Linter é”™è¯¯

`Instance of 'FieldInfo' has no 'append' member` - è¿™æ˜¯ Pylance çš„è¯¯æŠ¥ï¼Œä¸å½±å“å®é™…è¿è¡Œã€‚Pydantic çš„ `Field(default_factory=list)` ä¼šåœ¨è¿è¡Œæ—¶æ­£ç¡®åˆ›å»ºåˆ—è¡¨ã€‚

### æ•°æ®åº“è¿æ¥é”™è¯¯

ç¡®ä¿ MySQL å·²å¯åŠ¨å¹¶ä¸”é…ç½®æ­£ç¡®ï¼š

```bash
# æ£€æŸ¥é…ç½®
cat .env | grep MYSQL

# åˆå§‹åŒ–æ•°æ®åº“
python scripts/init_database.py
```

### LLM API é”™è¯¯

æ£€æŸ¥ API Key å’Œç½‘ç»œè¿æ¥ï¼š

```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $LLM_API_KEY

# ä½¿ç”¨ä¸­è½¬API
export LLM_BASE_URL="https://api.your-proxy.com/v1"
```

