"""
æµ‹è¯•æå–æç¤ºè¯ - å¯¹æ¯”åŸç‰ˆ vs å¢å¼ºç‰ˆ

ç”¨æ³•ï¼š
1. è¿è¡Œï¼špython test_extract.py
2. æŸ¥çœ‹è¾“å‡ºå¯¹æ¯”ç»“æœ

é…ç½®ï¼šè‡ªåŠ¨ä» .env æ–‡ä»¶è¯»å–
"""

import asyncio
import json
import os
import sys
from pathlib import Path
from typing import Dict, Any
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()


# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent

# æµ‹è¯•æ–‡ä»¶è·¯å¾„
TEST_FILE_PATH = PROJECT_ROOT / "tests" / "extract" / "test_extract_prompt" / "æ—ä¿Šæ°å¥³å‹ç…§ç‰‡ç»å¸¸è¢«è¯†åˆ«ä¸ºAIæ—ä¿Šæ°å®˜å®£æ‹æƒ….md"

# LLM é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
LLM_API_KEY = os.getenv("LLM_API_KEY", "")
LLM_BASE_URL = os.getenv("LLM_BASE_URL", "")
LLM_MODEL = os.getenv("LLM_MODEL", "qwen-plus")

# æç¤ºè¯æ–‡ä»¶è·¯å¾„
PROMPT_V1 = str(PROJECT_ROOT / "prompts" / "extract.yaml")
PROMPT_V2 = str(PROJECT_ROOT / "tests" / "extract" / "test_extract_prompt" / "extract_v2.yaml")


# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ° sys.path
sys.path.insert(0, str(PROJECT_ROOT))


async def test_prompt_extraction(
    test_file: str,
    prompt_file: str,
    version_name: str
) -> Dict[str, Any]:
    """
    æµ‹è¯•å•ä¸ªæç¤ºè¯ç‰ˆæœ¬çš„æå–æ•ˆæœ

    Args:
        test_file: æµ‹è¯•æ–‡ä»¶è·¯å¾„
        prompt_file: æç¤ºè¯æ–‡ä»¶è·¯å¾„
        version_name: ç‰ˆæœ¬åç§°ï¼ˆç”¨äºè¾“å‡ºï¼‰

    Returns:
        æå–ç»“æœç»Ÿè®¡
    """
    print(f"\n{'='*80}")
    print(f"æµ‹è¯•ç‰ˆæœ¬: {version_name}")
    print(f"{'='*80}")
    print(f"æç¤ºè¯æ–‡ä»¶: {prompt_file}")
    print(f"æµ‹è¯•æ–‡ä»¶: {test_file}\n")

    # 1. è¯»å–æµ‹è¯•æ–‡ä»¶
    print("è¯»å–æµ‹è¯•æ–‡ä»¶...")
    try:
        with open(test_file, 'r', encoding='utf-8') as f:
            content = f.read()
        print(f"æ–‡ä»¶è¯»å–æˆåŠŸ ({len(content)} å­—ç¬¦, {len(content.splitlines())} è¡Œ)")
    except Exception as e:
        print(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return {"error": str(e)}

    # 2. åŠ è½½æç¤ºè¯
    print(f"\nåŠ è½½æç¤ºè¯...")
    try:
        from dataflow.core.prompt.manager import PromptManager

        # è·å–æç¤ºè¯æ‰€åœ¨ç›®å½•
        prompt_dir = Path(prompt_file).parent
        prompt_manager = PromptManager(prompts_dir=prompt_dir)

        # è¯»å–æç¤ºè¯å†…å®¹ç”¨äºæ˜¾ç¤º
        with open(prompt_file, 'r', encoding='utf-8') as f:
            prompt_content = f.read()

        print(f"æç¤ºè¯åŠ è½½æˆåŠŸ")
        print(f"   æç¤ºè¯é•¿åº¦: {len(prompt_content)} å­—ç¬¦")

    except Exception as e:
        print(f"æç¤ºè¯åŠ è½½å¤±è´¥: {e}")
        return {"error": str(e)}

    # 3. åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
    print(f"\nåˆå§‹åŒ– LLM å®¢æˆ·ç«¯...")
    try:
        from dataflow.core.ai.factory import create_llm_client
        from dataflow.core.ai.models import LLMMessage, LLMRole

        # åˆ›å»ºä¸´æ—¶é…ç½®
        model_config = {
            "model": LLM_MODEL,
            "api_key": LLM_API_KEY,
            "base_url": LLM_BASE_URL,
            "temperature": 0.3
        }

        llm_client = await create_llm_client(
            scenario='extract',
            model_config=model_config
        )

        print(f"LLM å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        print(f"   æ¨¡å‹: {LLM_MODEL}")

    except Exception as e:
        print(f"LLM å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        return {"error": str(e)}

    # 4. æ„å»ºæç¤ºè¯
    print(f"\næ„å»ºæç¤ºè¯...")

    # æå–åŸæ–‡å†…å®¹ï¼ˆæ¨¡æ‹Ÿåˆ†å—ï¼‰
    sections = [
        {
            "id": "section_1",
            "content": content
        }
    ]

    # æ„å»ºæç¤ºè¯å‚æ•°
    background = """ """

    # æ„å»ºå®ä½“ç±»å‹æè¿°
    entity_types = """
- **person** (äººç‰©): äººåï¼Œå¦‚æ—ä¿Šæ°
- **organization** (æœºæ„): ç»„ç»‡æœºæ„åç§°
- **location** (åœ°ç‚¹): åœ°ç†ä½ç½®åç§°
- **tags** (å…³é”®è¯): å…¶ä»–é‡è¦å…³é”®è¯
"""

    # æå–å€™é€‰å…³é”®è¯ï¼ˆç®€å•å–å‰100ä¸ªå­—ç¬¦ä½œä¸ºç¤ºä¾‹ï¼‰
    candidate_keywords = content[:100] if content else "æ— "

    # æ„å»ºè¾“å‡º schema
    output_schema = json.dumps({
        "title": "ç®€æ´æ ‡é¢˜",
        "summary": "ä¸€å¥è¯æ‘˜è¦",
        "content": "å®Œæ•´äº‹ä»¶å†…å®¹",
        "category": "åˆ†ç±»æ ‡ç­¾",
        "references": ["section.id"],
        "entities": [{"type": "ç±»å‹", "name": "åç§°", "description": "æè¿°"}],
        "is_valid": True
    }, ensure_ascii=False, indent=2)

    # æ¸²æŸ“æç¤ºè¯
    try:
        system_prompt = prompt_manager.render(
            "event_extraction" if version_name == "åŸç‰ˆ(v1)" else "event_extraction",
            background=background,
            entity_types=entity_types,
            candidate_keywords=candidate_keywords,
            output_schema=output_schema
        )

        user_input = {
            "type": "input",
            "name": "æµ‹è¯•è¾“å…¥",
            "description": "å™ªéŸ³è¿‡æ»¤æµ‹è¯•",
            "items": sections
        }

        print(f"âœ… æç¤ºè¯æ„å»ºæˆåŠŸ")
        print(f"   SYSTEM é•¿åº¦: {len(system_prompt)} å­—ç¬¦")
        print(f"   USER é•¿åº¦: {len(json.dumps(user_input, ensure_ascii=False))} å­—ç¬¦")

    except Exception as e:
        print(f"âŒ æç¤ºè¯æ„å»ºå¤±è´¥: {e}")
        return {"error": str(e)}

    # 5. è°ƒç”¨ LLM
    print(f"\n è°ƒç”¨ LLM è¿›è¡Œæå–...")
    try:
        from dataflow.core.ai.models import LLMMessage, LLMRole

        messages = [
            LLMMessage(role=LLMRole.SYSTEM, content=system_prompt),
            LLMMessage(role=LLMRole.USER, content=json.dumps(user_input, ensure_ascii=False))
        ]

        # å®šä¹‰å“åº” schema
        response_schema = {
            "type": "object",
            "properties": {
                "type": {"type": "string"},
                "name": {"type": "string"},
                "description": {"type": "string"},
                "items": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "title": {"type": "string"},
                            "summary": {"type": "string"},
                            "content": {"type": "string"},
                            "category": {"type": "string"},
                            "references": {"type": "array", "items": {"type": "string"}},
                            "entities": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "type": {"type": "string"},
                                        "name": {"type": "string"},
                                        "description": {"type": "string"}
                                    },
                                    "required": ["type", "name"]
                                }
                            },
                            "is_valid": {"type": "boolean"}
                        },
                        "required": ["title", "content", "is_valid"]
                    }
                }
            },
            "required": ["items"]
        }

        result = await llm_client.chat_with_schema(
            messages=messages,
            response_schema=response_schema,
            temperature=0.3
        )

        items = result.get("items", [])
        print(f"âœ… LLM è°ƒç”¨æˆåŠŸ")
        print(f"   æå–äº‹é¡¹æ•°: {len(items)}")

    except Exception as e:
        print(f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {"error": str(e)}

    # 6. åˆ†æç»“æœ
    print(f"\nç»“æœåˆ†æ:")
    print(f"{'-'*80}")

    valid_items = []
    invalid_items = []

    for item in items:
        if item.get("is_valid", True):
            valid_items.append(item)
        else:
            invalid_items.append(item)

    print(f"\næœ‰æ•ˆäº‹é¡¹: {len(valid_items)} ä¸ª")
    for i, item in enumerate(valid_items, 1):
        title = item.get("title", "")[:50]
        content_preview = item.get("content", "")[:80]
        print(f"   {i}. {title}")
        print(f"      å†…å®¹: {content_preview}...")

    print(f"\nâŒ è¿‡æ»¤äº‹é¡¹: {len(invalid_items)} ä¸ª")
    for i, item in enumerate(invalid_items[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
        title = item.get("title", "")[:50]
        print(f"   {i}. {title}")

    if len(invalid_items) > 10:
        print(f"   ... è¿˜æœ‰ {len(invalid_items) - 10} ä¸ªè¢«è¿‡æ»¤")

    # 7. ç‰¹å®šå™ªéŸ³æ£€æŸ¥
    print(f"\nğŸ” å™ªéŸ³è¿‡æ»¤æ£€æŸ¥:")
    noise_keywords = [
        "æ–°æµªé¦–é¡µ", "æ–°æµªæ–°é—»å®¢æˆ·ç«¯", "ç”¨æˆ·æ“ä½œå…¥å£",
        "ç‚¹å‡»æŸ¥çœ‹", "æ¨èé˜…è¯»", "é˜…è¯»æ’è¡Œæ¦œ",
        "æŠ•èµ„çƒ­ç‚¹", "åŠ è½½ä¸­", "æˆ‘çš„æ”¶è—"
    ]

    filtered_noises = []
    for item in invalid_items:
        title = item.get("title", "")
        for keyword in noise_keywords:
            if keyword in title:
                filtered_noises.append(keyword)
                break

    if filtered_noises:
        print(f"æˆåŠŸè¿‡æ»¤çš„å™ªéŸ³: {', '.join(set(filtered_noises))}")
    else:
        print(f"âš ï¸ æœªæ£€æµ‹åˆ°å…¸å‹å™ªéŸ³è¢«è¿‡æ»¤")

    # è¿”å›ç»Ÿè®¡
    return {
        "version": version_name,
        "total": len(items),
        "valid": len(valid_items),
        "invalid": len(invalid_items),
        "valid_items": valid_items,
        "invalid_items": invalid_items,
        "filtered_noises": filtered_noises
    }


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("="*80)
    print("æç¤ºè¯å¯¹æ¯”æµ‹è¯• - å™ªéŸ³è¿‡æ»¤æ•ˆæœ")
    print("="*80)
    print(f"\næµ‹è¯•æ–‡ä»¶: {TEST_FILE_PATH}")
    print(f"LLM æ¨¡å‹: {LLM_MODEL}")
    print(f"LLM åœ°å€: {LLM_BASE_URL}")

    # æ£€æŸ¥æµ‹è¯•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(TEST_FILE_PATH).exists():
        print(f"\nâŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {TEST_FILE_PATH}")
        return

    # æµ‹è¯•åŸç‰ˆæç¤ºè¯
    result_v1 = await test_prompt_extraction(
        test_file=TEST_FILE_PATH,
        prompt_file=PROMPT_V1,
        version_name="åŸç‰ˆ(v1)"
    )

    # ç­‰å¾…ä¸€ä¸‹é¿å… API é™æµ
    await asyncio.sleep(2)

    # æµ‹è¯•å¢å¼ºç‰ˆæç¤ºè¯
    result_v2 = await test_prompt_extraction(
        test_file=TEST_FILE_PATH,
        prompt_file=PROMPT_V2,
        version_name="å¢å¼ºç‰ˆ(v2)"
    )

    # å¯¹æ¯”ç»“æœ
    print(f"\n{'='*80}")
    print(f"å¯¹æ¯”ç»“æœ")
    print(f"{'='*80}\n")

    if "error" in result_v1:
        print(f"åŸç‰ˆæµ‹è¯•å¤±è´¥: {result_v1['error']}")
    elif "error" in result_v2:
        print(f"å¢å¼ºç‰ˆæµ‹è¯•å¤±è´¥: {result_v2['error']}")
    else:
        print(f"{'æŒ‡æ ‡':<20} {'åŸç‰ˆ(v1)':<15} {'å¢å¼ºç‰ˆ(v2)':<15} {'å¯¹æ¯”':<15}")
        print(f"{'-'*80}")

        # æ€»äº‹é¡¹æ•°
        total_v1 = result_v1.get("total", 0)
        total_v2 = result_v2.get("total", 0)
        print(f"{'æ€»æå–äº‹é¡¹':<20} {total_v1:<15} {total_v2:<15} {total_v2 - total_v1:+d}")

        # æœ‰æ•ˆäº‹é¡¹
        valid_v1 = result_v1.get("valid", 0)
        valid_v2 = result_v2.get("valid", 0)
        print(f"{'æœ‰æ•ˆäº‹é¡¹':<20} {valid_v1:<15} {valid_v2:<15} {valid_v2 - valid_v1:+d}")

        # è¿‡æ»¤äº‹é¡¹
        invalid_v1 = result_v1.get("invalid", 0)
        invalid_v2 = result_v2.get("invalid", 0)
        improvement = invalid_v2 - invalid_v1
        print(f"{'è¿‡æ»¤äº‹é¡¹':<20} {invalid_v1:<15} {invalid_v2:<15} {improvement:+d}")

        # è¿‡æ»¤ç‡
        rate_v1 = (invalid_v1 / total_v1 * 100) if total_v1 > 0 else 0
        rate_v2 = (invalid_v2 / total_v2 * 100) if total_v2 > 0 else 0
        print(f"{'è¿‡æ»¤ç‡':<20} {rate_v1:.1f}%{'':<10} {rate_v2:.1f}%{'':<10} {rate_v2 - rate_v1:+.1f}%")

        # å™ªéŸ³è¿‡æ»¤
        noises_v1 = len(result_v1.get("filtered_noises", []))
        noises_v2 = len(result_v2.get("filtered_noises", []))
        print(f"{'å…¸å‹å™ªéŸ³è¿‡æ»¤':<20} {noises_v1:<15} {noises_v2:<15} {noises_v2 - noises_v1:+d}")

        print(f"\n{'='*80}")
        print(f"ğŸ’¡ ç»“è®º")
        print(f"{'='*80}\n")

        if improvement > 0:
            print(f"âœ… å¢å¼ºç‰ˆæ•ˆæœæ›´å¥½ï¼")
            print(f"   - å¤šè¿‡æ»¤äº† {improvement} ä¸ªå™ªéŸ³äº‹é¡¹")
            print(f"   - è¿‡æ»¤ç‡æå‡ {rate_v2 - rate_v1:.1f}%")
            if noises_v2 > noises_v1:
                print(f"   - å…¸å‹å™ªéŸ³è¯†åˆ«å¢åŠ  {noises_v2 - noises_v1} ä¸ª")
        elif improvement == 0:
            print(f"âš ï¸ ä¸¤ä¸ªç‰ˆæœ¬è¿‡æ»¤æ•ˆæœç›¸åŒ")
        else:
            print(f"âŒ å¢å¼ºç‰ˆæ•ˆæœæ›´å·®ï¼Œè¿‡æ»¤å‡å°‘äº† {-improvement} ä¸ª")

        print(f"\nå»ºè®®:")
        if improvement > 5:
            print(f"  â†’ å»ºè®®ä½¿ç”¨å¢å¼ºç‰ˆæç¤ºè¯")
        elif improvement > 0:
            print(f"  â†’ å¢å¼ºç‰ˆç•¥æœ‰æå‡ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨")
        else:
            print(f"  â†’ å»ºè®®ç»§ç»­ä½¿ç”¨åŸç‰ˆæç¤ºè¯")

    print(f"\n{'='*80}")
    print(f"æµ‹è¯•å®Œæˆï¼")
    print(f"{'='*80}\n")


if __name__ == "__main__":
    asyncio.run(main())
