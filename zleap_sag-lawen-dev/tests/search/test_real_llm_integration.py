"""
çœŸå®LLMé›†æˆæµ‹è¯•

ä¸“é—¨ç”¨äºæµ‹è¯•Stage1æœç´¢ä¸­çš„å®ä½“æå–åŠŸèƒ½ä¸çœŸå®LLMçš„é›†æˆ
"""

import pytest
import asyncio
import time
from typing import List, Dict, Any

# æ ‡è®°ä¸ºé›†æˆæµ‹è¯•
pytestmark = [pytest.mark.asyncio, pytest.mark.integration]


class TestRealLLMIntegration:
    """çœŸå®LLMé›†æˆæµ‹è¯•ç±»"""

    @pytest.fixture(scope="class")
    async def searcher(self):
        """åˆå§‹åŒ–çœŸå®çš„æœç´¢å™¨å®ä¾‹"""
        try:
            from dataflow.core.ai.factory import create_llm_client
            from dataflow.core.config import get_settings
            from dataflow.core.prompt.manager import PromptManager
            from dataflow.modules.search.stage1 import Stage1Searcher

            # æ£€æŸ¥é…ç½®
            settings = get_settings()
            if not settings.llm_api_key:
                pytest.skip("æœªé…ç½®LLM APIå¯†é’¥ï¼Œè·³è¿‡é›†æˆæµ‹è¯•")

            # ä½¿ç”¨å·¥å‚æ¨¡å¼åˆå§‹åŒ–ç»„ä»¶
            llm_client = create_llm_client(
                provider="openai",
                model=settings.llm_model,
                api_key=settings.llm_api_key,
                base_url=settings.llm_base_url,
                with_retry=True
            )
            prompt_manager = PromptManager()
            searcher = Stage1Searcher(llm_client, prompt_manager)

            yield searcher

        except Exception as e:
            pytest.skip(f"åˆå§‹åŒ–å¤±è´¥: {e}")

    @pytest.mark.integration
    async def test_simple_person_location_query(self, searcher):
        """æµ‹è¯•ç®€å•çš„äººå‘˜å’Œåœ°ç‚¹æŸ¥è¯¢"""
        query = "å¼ ä¸‰åœ¨åŒ—äº¬å·¥ä½œ"

        start_time = time.time()
        attributes = await searcher._extract_attributes_from_query(query)
        response_time = time.time() - start_time

        # éªŒè¯åŸºæœ¬è¦æ±‚
        assert isinstance(attributes, list)
        assert response_time < 10.0  # å“åº”æ—¶é—´åº”è¯¥åˆç†

        # éªŒè¯æå–åˆ°çš„äººå‘˜
        person_attrs = [attr for attr in attributes if attr['type'] == 'person']
        assert len(person_attrs) >= 1

        # éªŒè¯æå–åˆ°çš„åœ°ç‚¹
        location_attrs = [attr for attr in attributes if attr['type'] == 'location']
        assert len(location_attrs) >= 1

        print(f"âœ… ç®€å•æŸ¥è¯¢æµ‹è¯•é€šè¿‡ - å“åº”æ—¶é—´: {response_time:.2f}s, æå–å±æ€§: {len(attributes)}")
        print(f"ğŸ“‹ æå–åˆ°çš„å±æ€§è¯¦æƒ…:")
        for i, attr in enumerate(attributes, 1):
            print(f"  {i}. {attr}")
        print(f"ğŸ¯ æŸ¥è¯¢: '{query}'")

    @pytest.mark.integration
    async def test_complex_multi_entity_query(self, searcher):
        """æµ‹è¯•å¤æ‚çš„å¤šå®ä½“æŸ¥è¯¢"""
        query = "2024å¹´æå››åœ¨ä¸Šæµ·å’Œæ·±åœ³ç ”ç©¶AIå’ŒåŒºå—é“¾æŠ€æœ¯"

        start_time = time.time()
        attributes = await searcher._extract_attributes_from_query(query)
        response_time = time.time() - start_time

        # éªŒè¯æå–åˆ°çš„å®ä½“ç±»å‹
        entity_types = set(attr['type'] for attr in attributes)

        # åº”è¯¥åŒ…å«æ—¶é—´ã€äººå‘˜ã€åœ°ç‚¹ã€è¯é¢˜
        expected_types = ['time', 'person', 'location', 'topic']
        found_types = [etype for etype in expected_types if etype in entity_types]

        assert len(found_types) >= 2, f"åº”è¯¥è‡³å°‘æå–åˆ°2ç§å®ä½“ç±»å‹ï¼Œå®é™…æå–åˆ°: {entity_types}"
        assert response_time < 15.0

        print(f"âœ… å¤æ‚æŸ¥è¯¢æµ‹è¯•é€šè¿‡ - å“åº”æ—¶é—´: {response_time:.2f}s, å®ä½“ç±»å‹: {entity_types}")

    @pytest.mark.integration
    async def test_technical_topic_query(self, searcher):
        """æµ‹è¯•æŠ€æœ¯ä¸»é¢˜æŸ¥è¯¢"""
        query = "å¦‚ä½•æé«˜æœºå™¨å­¦ä¹ æ¨¡å‹çš„å‡†ç¡®ç‡ï¼Ÿ"

        start_time = time.time()
        attributes = await searcher._extract_attributes_from_query(query)
        response_time = time.time() - start_time

        # éªŒè¯æå–åˆ°æŠ€æœ¯ç›¸å…³å®ä½“
        tech_attrs = [attr for attr in attributes if attr['type'] in ['topic', 'action']]

        assert len(tech_attrs) >= 1, "åº”è¯¥æå–åˆ°æŠ€æœ¯ç›¸å…³çš„å®ä½“"
        assert response_time < 10.0

        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›¸å…³æŠ€æœ¯è¯æ±‡
        extracted_names = [attr['name'] for attr in attributes]
        tech_keywords = ['æœºå™¨å­¦ä¹ ', 'æ¨¡å‹', 'å‡†ç¡®ç‡']

        found_keywords = [kw for kw in tech_keywords
                         if any(kw in name or name in kw for name in extracted_names)]

        print(f"âœ… æŠ€æœ¯æŸ¥è¯¢æµ‹è¯•é€šè¿‡ - å“åº”æ—¶é—´: {response_time:.2f}s, æå–å±æ€§: {len(attributes)}")
        print(f"   æå–åˆ°çš„æŠ€æœ¯è¯æ±‡: {found_keywords}")

    @pytest.mark.integration
    async def test_edge_cases(self, searcher):
        """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
        edge_cases = [
            ("", "ç©ºæŸ¥è¯¢"),
            ("a", "å•å­—ç¬¦æŸ¥è¯¢"),
            ("è¿™æ˜¯ä¸€ä¸ªéå¸¸é•¿çš„æŸ¥è¯¢ï¼ŒåŒ…å«å¾ˆå¤šä¸ç›¸å…³çš„æè¿°æ€§æ–‡å­—ï¼Œç”¨æ¥æµ‹è¯•ç³»ç»Ÿåœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶çš„æ€§èƒ½å’Œå‡†ç¡®æ€§" * 3, "è¶…é•¿æŸ¥è¯¢"),
            ("123456789", "çº¯æ•°å­—æŸ¥è¯¢"),
            ("!@#$%^&*()", "ç‰¹æ®Šå­—ç¬¦æŸ¥è¯¢"),
            ("Hello World", "è‹±æ–‡æŸ¥è¯¢"),
        ]

        for query, description in edge_cases:
            start_time = time.time()
            try:
                attributes = await searcher._extract_attributes_from_query(query)
                response_time = time.time() - start_time

                # éªŒè¯ä¸ä¼šå´©æºƒ
                assert isinstance(attributes, list)
                assert response_time < 20.0

                print(f"âœ… {description}æµ‹è¯•é€šè¿‡ - å“åº”æ—¶é—´: {response_time:.2f}s, æå–å±æ€§: {len(attributes)}")

            except Exception as e:
                print(f"âš ï¸ {description}æµ‹è¯•å‡ºç°å¼‚å¸¸: {e}")
                # è¾¹ç•Œæƒ…å†µä¸‹å‡ºç°å¼‚å¸¸æ˜¯å¯ä»¥æ¥å—çš„ï¼Œä½†ä¸åº”è¯¥å´©æºƒæ•´ä¸ªç³»ç»Ÿ

    @pytest.mark.integration
    async def test_confidence_scores(self, searcher):
        """æµ‹è¯•ç½®ä¿¡åº¦è¯„ä¼°"""
        query = "ç‹äº”æ•™æˆåœ¨æ¸…åå¤§å­¦è¿›è¡Œæ·±åº¦å­¦ä¹ ç ”ç©¶"

        attributes = await searcher._extract_attributes_from_query(query)

        # éªŒè¯ç½®ä¿¡åº¦æ ¼å¼
        for attr in attributes:
            assert 'confidence' in attr
            assert isinstance(attr['confidence'], (int, float))
            assert 0.0 <= attr['confidence'] <= 1.0

        # éªŒè¯é‡è¦æ€§è¯„ä¼°
        for attr in attributes:
            assert 'importance' in attr
            assert attr['importance'] in ['high', 'medium', 'low']

        print(f"âœ… ç½®ä¿¡åº¦æµ‹è¯•é€šè¿‡ - æå–å±æ€§: {len(attributes)}")

    @pytest.mark.integration
    async def test_fallback_mechanism(self, searcher):
        """æµ‹è¯•å›é€€æœºåˆ¶"""
        # è¿™é‡Œæˆ‘ä»¬æ— æ³•ç›´æ¥è§¦å‘å›é€€æœºåˆ¶ï¼Œä½†å¯ä»¥æµ‹è¯•æ–¹æ³•çš„å¥å£®æ€§
        queries = [
            "æ­£å¸¸çš„æŸ¥è¯¢å†…å®¹",
            "åŒ…å«ä¸€äº›æ¨¡ç³Šè¡¨è¿°çš„æŸ¥è¯¢",
            "å¯èƒ½æå–ä¸åˆ°å®ä½“çš„æŸ¥è¯¢è¯­å¥",
        ]

        for query in queries:
            try:
                attributes = await searcher._extract_attributes_from_query(query)
                # ä¸ç®¡ç»“æœå¦‚ä½•ï¼Œéƒ½ä¸åº”è¯¥å´©æºƒ
                assert isinstance(attributes, list)

            except Exception as e:
                pytest.fail(f"æŸ¥è¯¢ '{query}' å¯¼è‡´å¼‚å¸¸: {e}")

        print(f"âœ… å›é€€æœºåˆ¶æµ‹è¯•é€šè¿‡ - æ‰€æœ‰æŸ¥è¯¢éƒ½èƒ½æ­£å¸¸å¤„ç†")


# æ€§èƒ½åŸºå‡†æµ‹è¯•
@pytest.mark.integration
@pytest.mark.slow
async def test_performance_benchmark():
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    pytest.skip("æ€§èƒ½åŸºå‡†æµ‹è¯•éœ€è¦å•ç‹¬è¿è¡Œ")

    try:
        from dataflow.core.ai.factory import create_llm_client
        from dataflow.core.config import get_settings
        from dataflow.core.prompt.manager import PromptManager
        from dataflow.modules.search.stage1 import Stage1Searcher

        # åˆå§‹åŒ–
        settings = get_settings()
        if not settings.llm_api_key:
            pytest.skip("æœªé…ç½®LLM APIå¯†é’¥")

        llm_client = create_llm_client(
            provider="openai",
            model=settings.llm_model,
            api_key=settings.llm_api_key,
            base_url=settings.llm_base_url,
            with_retry=True
        )
        prompt_manager = PromptManager()
        searcher = Stage1Searcher(llm_client, prompt_manager)

        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "å¼ ä¸‰åœ¨åŒ—äº¬å·¥ä½œ",
            "æå››ç ”ç©¶äººå·¥æ™ºèƒ½æŠ€æœ¯",
            "2024å¹´åœ¨ä¸Šæµ·ä¸¾åŠæŠ€æœ¯å¤§ä¼š",
            "å¦‚ä½•æé«˜æœºå™¨å­¦ä¹ æ¨¡å‹æ€§èƒ½",
            "æ·±åº¦å­¦ä¹ æ¡†æ¶å¯¹æ¯”åˆ†æ"
        ]

        # æ€§èƒ½æµ‹è¯•
        total_time = 0
        successful_calls = 0

        for query in test_queries:
            start_time = time.time()
            try:
                attributes = await searcher._extract_attributes_from_query(query)
                response_time = time.time() - start_time
                total_time += response_time
                successful_calls += 1

                print(f"æŸ¥è¯¢: {query[:20]}... - å“åº”æ—¶é—´: {response_time:.2f}s")

            except Exception as e:
                print(f"æŸ¥è¯¢å¤±è´¥: {query[:20]}... - é”™è¯¯: {e}")

        if successful_calls > 0:
            avg_response_time = total_time / successful_calls
            print(f"å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}s")
            print(f"æˆåŠŸç‡: {successful_calls}/{len(test_queries)} ({successful_calls/len(test_queries)*100:.1f}%)")

            # æ€§èƒ½æ–­è¨€
            assert avg_response_time < 5.0, f"å¹³å‡å“åº”æ—¶é—´è¿‡é•¿: {avg_response_time:.2f}s"
            assert successful_calls >= len(test_queries) * 0.8, "æˆåŠŸç‡è¿‡ä½"

    except Exception as e:
        pytest.skip(f"æ€§èƒ½åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œé›†æˆæµ‹è¯•
    print("ğŸ§ª å¼€å§‹è¿è¡ŒçœŸå®LLMé›†æˆæµ‹è¯•")
    print("=" * 60)

    # å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°é€‰æ‹©è¿è¡Œç‰¹å®šæµ‹è¯•
    import sys

    if len(sys.argv) > 1:
        test_name = sys.argv[1]
        if test_name == "performance":
            asyncio.run(test_performance_benchmark())
        else:
            print(f"æœªçŸ¥çš„æµ‹è¯•åç§°: {test_name}")
    else:
        # è¿è¡Œpytest
        pytest.main([__file__, "-v", "-s"])