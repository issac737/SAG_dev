"""
HotpotQA æ•°æ®é›†ä¸æ£€ç´¢ç³»ç»Ÿé›†æˆå·¥å…·

åŠŸèƒ½ï¼š
1. å°† HotpotQA æ ·æœ¬è½¬æ¢ä¸º MD æ ¼å¼
2. åˆ›å»ºä¿¡æ¯æº
3. ä¸Šä¼  MD æ–‡ä»¶åˆ°ä¿¡æ¯æº
4. ç­‰å¾…äº‹é¡¹åˆ›å»ºå®Œæˆ
5. æ ¹æ®é—®é¢˜æœç´¢äº‹é¡¹

ä½¿ç”¨ç¤ºä¾‹:
    from hotpotqa_pipeline import HotpotQAPipeline

    pipeline = HotpotQAPipeline(
        api_base_url="http://localhost:8000/api/v1",
        dataset_path="path/to/hotpotqa"
    )

    # è¿è¡Œå®Œæ•´æµç¨‹
    results = pipeline.run_pipeline(sample_limit=5)
"""

import json
import time
import requests
from pathlib import Path
from typing import Dict, List, Any, Optional
from hotpotqa_loader import HotpotQALoader


class HotpotQAPipeline:
    """HotpotQA ä¸æ£€ç´¢ç³»ç»Ÿé›†æˆç®¡é“"""

    def __init__(
        self,
        api_base_url: str = "http://localhost:8000/api/v1",
        dataset_path: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–ç®¡é“

        Args:
            api_base_url: API åŸºç¡€ URL
            dataset_path: HotpotQA æ•°æ®é›†è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        self.api_base_url = api_base_url.rstrip('/')
        self.dataset_path = dataset_path
        self.loader = HotpotQALoader(dataset_path) if dataset_path else None

    def sample_to_markdown(self, sample: Dict[str, Any]) -> str:
        """
        å°†å•ä¸ª HotpotQA æ ·æœ¬è½¬æ¢ä¸º Markdown æ ¼å¼

        Args:
            sample: HotpotQA æ ·æœ¬

        Returns:
            Markdown æ ¼å¼çš„æ–‡æœ¬
        """
        md_lines = []

        # æ ‡é¢˜ï¼šä½¿ç”¨é—®é¢˜ä½œä¸ºä¸»æ ‡é¢˜
        md_lines.append(f"# {sample['question']}\n")

        # å…ƒæ•°æ®
        md_lines.append("## å…ƒæ•°æ®\n")
        md_lines.append(f"- **é—®é¢˜ID**: {sample['id']}")
        md_lines.append(f"- **é—®é¢˜ç±»å‹**: {sample['type']}")
        md_lines.append(f"- **éš¾åº¦ç­‰çº§**: {sample['level']}")
        md_lines.append(f"- **æ ‡å‡†ç­”æ¡ˆ**: {sample['answer']}\n")

        # ä¸Šä¸‹æ–‡æ–‡æ¡£
        md_lines.append("## ä¸Šä¸‹æ–‡æ–‡æ¡£\n")
        context = sample['context']

        for i, (title, sentences) in enumerate(zip(context['title'], context['sentences']), 1):
            md_lines.append(f"### {i}. {title}\n")

            # å°†å¥å­åˆå¹¶ä¸ºæ®µè½
            content = " ".join(sentences)
            md_lines.append(f"{content}\n")

        # æ”¯æŒæ€§äº‹å®ï¼ˆå¯é€‰ï¼Œç”¨äºéªŒè¯ï¼‰
        if self.loader:
            supporting_sentences = self.loader.get_supporting_sentences(sample)
            if supporting_sentences:
                md_lines.append("## æ”¯æŒæ€§äº‹å®\n")
                for i, sent in enumerate(supporting_sentences, 1):
                    md_lines.append(f"{i}. {sent}")
                md_lines.append("")

        return "\n".join(md_lines)

    def save_sample_to_md(
        self,
        sample: Dict[str, Any],
        output_path: str
    ) -> str:
        """
        ä¿å­˜æ ·æœ¬ä¸º MD æ–‡ä»¶

        Args:
            sample: HotpotQA æ ·æœ¬
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        md_content = self.sample_to_markdown(sample)

        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(md_content)

        print(f"âœ“ MD æ–‡ä»¶å·²ä¿å­˜: {output_file}")
        return str(output_file)

    def create_source(
        self,
        name: str = "HotpotQA æµ‹è¯•æ•°æ®é›†",
        description: str = "ç”¨äºæµ‹è¯•çš„ HotpotQA é—®ç­”æ•°æ®",
        config: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        åˆ›å»ºä¿¡æ¯æº

        Args:
            name: ä¿¡æ¯æºåç§°
            description: ä¿¡æ¯æºæè¿°
            config: é…ç½®ä¿¡æ¯

        Returns:
            åˆ›å»ºçš„ä¿¡æ¯æºæ•°æ®ï¼ˆåŒ…å« source_config_idï¼‰
        """
        url = f"{self.api_base_url}/sources"

        payload = {
            "name": name,
            "description": description,
            "config": config or {
                "focus": ["é—®ç­”", "çŸ¥è¯†æ£€ç´¢"],
                "language": "zh"
            }
        }

        print(f"ğŸ“ åˆ›å»ºä¿¡æ¯æº: {name}")
        response = requests.post(url, json=payload)
        response.raise_for_status()

        result = response.json()
        source_config_id = result['data']['id']
        print(f"âœ… ä¿¡æ¯æºåˆ›å»ºæˆåŠŸ: {source_config_id}\n")

        return result['data']

    def _match_document(
        self,
        documents: list,
        filename: str,
        upload_time,
        time_tolerance_seconds: int = 300
    ) -> Optional[Dict]:
        """
        ä»æ–‡æ¡£åˆ—è¡¨ä¸­åŒ¹é…ç›®æ ‡æ–‡æ¡£

        åŒ¹é…è§„åˆ™ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
        1. åˆ›å»ºæ—¶é—´åœ¨ä¸Šä¼ æ—¶é—´å‰å 5 åˆ†é’Ÿå†…
        2. æ–‡ä»¶ååŒ¹é…ï¼ˆæ ‡é¢˜åŒ…å«æ–‡ä»¶åæˆ–æ–‡ä»¶ååŒ…å«æ ‡é¢˜ï¼‰
        3. ä¼˜å…ˆè¿”å›æœ€æ–°çš„æ–‡æ¡£

        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            filename: ç›®æ ‡æ–‡ä»¶å
            upload_time: ä¸Šä¼ æ—¶é—´ï¼ˆUTCï¼‰
            time_tolerance_seconds: æ—¶é—´å®¹å·®ï¼ˆç§’ï¼‰

        Returns:
            åŒ¹é…çš„æ–‡æ¡£ï¼Œå¦‚æœæ²¡æ‰¾åˆ°è¿”å› None
        """
        from datetime import datetime

        # é¢„å¤„ç†æ–‡ä»¶åï¼ˆå»é™¤æ‰©å±•åï¼‰
        filename_base = Path(filename).stem

        candidates = []

        for doc in documents:
            doc_id = doc.get("id", "")
            doc_title = doc.get("title", "")
            doc_created_time = doc.get("created_time", "")

            # è§£æåˆ›å»ºæ—¶é—´
            try:
                # ISO 8601 æ ¼å¼: "2024-01-01T10:00:00"
                doc_time = datetime.fromisoformat(
                    doc_created_time.replace('Z', '+00:00'))
            except (ValueError, AttributeError):
                print(f"      âš ï¸  æ— æ³•è§£ææ—¶é—´: {doc_created_time}")
                continue

            # æ—¶é—´åŒ¹é…ï¼šåœ¨ä¸Šä¼ æ—¶é—´å‰å time_tolerance_seconds ç§’å†…
            time_diff = abs((doc_time - upload_time).total_seconds())
            is_time_match = time_diff <= time_tolerance_seconds

            # æ–‡ä»¶ååŒ¹é…ï¼ˆå®½æ¾åŒ¹é…ï¼‰
            is_name_match = (
                filename_base.lower() in doc_title.lower() or
                doc_title.lower() in filename_base.lower() or
                filename.lower() in doc_title.lower()
            )

            print(f"      æ£€æŸ¥: {doc_title[:40]}...")
            print(
                f"         æ—¶é—´å·®: {time_diff:.1f}ç§’ ({'âœ“' if is_time_match else 'âœ—'})")
            print(f"         åç§°åŒ¹é…: {'âœ“' if is_name_match else 'âœ—'}")

            # å¦‚æœæ—¶é—´åŒ¹é…ï¼ŒåŠ å…¥å€™é€‰ï¼ˆæ”¾å®½æ¡ä»¶ï¼Œä¸å¼ºåˆ¶åç§°åŒ¹é…ï¼‰
            if is_time_match:
                candidates.append({
                    "doc": doc,
                    "time_diff": time_diff,
                    "name_match": is_name_match
                })
                print(f"         â†’ åŠ å…¥å€™é€‰")

        # å¦‚æœæœ‰å€™é€‰ï¼Œä¼˜å…ˆé€‰æ‹©åç§°åŒ¹é…çš„ï¼Œå…¶æ¬¡é€‰æ‹©æ—¶é—´æœ€è¿‘çš„
        if candidates:
            # å…ˆæŒ‰åç§°åŒ¹é…æ’åºï¼Œå†æŒ‰æ—¶é—´æ’åº
            candidates.sort(key=lambda x: (
                not x["name_match"], x["time_diff"]))
            best_match = candidates[0]["doc"]
            print(f"\n      ğŸ¯ æœ€ä½³åŒ¹é…: {best_match['id']}")
            return best_match

        return None

    def _find_document_from_list(
        self,
        source_config_id: str,
        filename: str,
        upload_time,
        max_attempts: int = 10,
        interval: int = 2
    ) -> str:
        """
        ä»æ–‡æ¡£åˆ—è¡¨ä¸­æŸ¥æ‰¾åˆšä¸Šä¼ çš„æ–‡æ¡£

        Args:
            source_config_id: ä¿¡æ¯æº ID
            filename: ä¸Šä¼ çš„æ–‡ä»¶å
            upload_time: ä¸Šä¼ æ—¶é—´ï¼ˆUTCï¼‰
            max_attempts: æœ€å¤§å°è¯•æ¬¡æ•°
            interval: æ¯æ¬¡å°è¯•é—´éš”ï¼ˆç§’ï¼‰

        Returns:
            article_id: æ–‡æ¡£ ID

        Raises:
            ValueError: æ‰¾ä¸åˆ°æ–‡æ¡£
        """
        print(f"   ğŸ” ä»æ–‡æ¡£åˆ—è¡¨æŸ¥æ‰¾...")

        for attempt in range(1, max_attempts + 1):
            print(f"\n   å°è¯• {attempt}/{max_attempts}...")

            # ç­‰å¾…åç«¯å¤„ç†ï¼ˆç»™æ•°æ®åº“æ’å…¥ç•™æ—¶é—´ï¼‰
            if attempt > 1:
                time.sleep(interval)

            try:
                # è°ƒç”¨åˆ—è¡¨ APIï¼ˆæ¨¡ä»¿ Web ç«¯çš„ getDocumentsï¼‰
                response = requests.get(
                    f"{self.api_base_url}/sources/{source_config_id}/documents",
                    params={"page": 1, "page_size": 20},
                    timeout=10
                )

                response.raise_for_status()
                result = response.json()

                documents = result.get("data", [])
                print(f"      è·å–åˆ° {len(documents)} ä¸ªæ–‡æ¡£")

                # æŸ¥æ‰¾åŒ¹é…çš„æ–‡æ¡£
                matched_doc = self._match_document(
                    documents=documents,
                    filename=filename,
                    upload_time=upload_time
                )

                if matched_doc:
                    article_id = matched_doc["id"]
                    print(f"\n   âœ… æ‰¾åˆ°åŒ¹é…æ–‡æ¡£!")
                    print(f"      Article ID: {article_id}")
                    print(
                        f"      æ ‡é¢˜: {matched_doc.get('title', 'N/A')[:60]}...")
                    print(f"      çŠ¶æ€: {matched_doc.get('status', 'N/A')}")
                    return article_id

                print(f"      â³ æœªæ‰¾åˆ°åŒ¹é…æ–‡æ¡£ï¼Œç»§ç»­ç­‰å¾…...")

            except requests.exceptions.RequestException as e:
                print(f"      âš ï¸  è¯·æ±‚å¤±è´¥: {e}")
                if attempt == max_attempts:
                    raise

        # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
        raise ValueError(
            f"æ— æ³•ä»æ–‡æ¡£åˆ—è¡¨ä¸­æ‰¾åˆ°åˆšä¸Šä¼ çš„æ–‡ä»¶: {filename}\n"
            f"å·²å°è¯• {max_attempts} æ¬¡ï¼Œæ¯æ¬¡é—´éš” {interval} ç§’\n"
            f"å¯èƒ½åŸå› ï¼š\n"
            f"1. åç«¯å¤„ç†å¼‚å¸¸ï¼ˆæ£€æŸ¥æ—¥å¿—ï¼‰\n"
            f"2. æ–‡ä»¶æœªæˆåŠŸæ’å…¥æ•°æ®åº“\n"
            f"3. auto_process å‚æ•°æœªç”Ÿæ•ˆ"
        )

    def get_document_by_filename(
        self,
        source_config_id: str,
        filename: str,
        max_wait: int = 30
    ) -> Optional[str]:
        """
        é€šè¿‡æ–‡ä»¶åæŸ¥è¯¢æ–‡æ¡£ IDï¼ˆè½®è¯¢æ–¹å¼ï¼‰
        å·²å¼ƒç”¨ï¼šæ¨èç›´æ¥ä½¿ç”¨ _find_document_from_list

        Args:
            source_config_id: ä¿¡æ¯æº ID
            filename: æ–‡ä»¶å
            max_wait: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            article_idï¼Œå¦‚æœæ‰¾ä¸åˆ°è¿”å› None
        """
        from datetime import datetime
        upload_time = datetime.utcnow()
        try:
            return self._find_document_from_list(
                source_config_id=source_config_id,
                filename=filename,
                upload_time=upload_time,
                max_attempts=max_wait // 2,
                interval=2
            )
        except ValueError:
            return None

    def upload_document(
        self,
        source_config_id: str,
        file_path: str,
        background: str = "HotpotQA é—®ç­”æ•°æ®é›†æ–‡æ¡£",
        auto_process: bool = True
    ) -> Dict[str, Any]:
        """
        ä¸Šä¼  MD æ–‡ä»¶åˆ°ä¿¡æ¯æº
        æ¨¡ä»¿ Web ç«¯é€»è¾‘ï¼šä¸Šä¼  â†’ å°è¯•è·å– article_id â†’ å¤±è´¥åˆ™æŸ¥è¯¢åˆ—è¡¨

        Args:
            source_config_id: ä¿¡æ¯æº ID
            file_path: MD æ–‡ä»¶è·¯å¾„
            background: æ–‡æ¡£èƒŒæ™¯æè¿°
            auto_process: æ˜¯å¦è‡ªåŠ¨å¤„ç†

        Returns:
            ä¸Šä¼ ç»“æœï¼ˆåŒ…å« article_id å’Œè·å–æ–¹å¼ï¼‰
        """
        from datetime import datetime

        url = f"{self.api_base_url}/sources/{source_config_id}/documents/upload"
        filename = Path(file_path).name

        print(f"ğŸ“¤ ä¸Šä¼ æ–‡ä»¶: {filename}")

        # è®°å½•ä¸Šä¼ å¼€å§‹æ—¶é—´ï¼ˆç”¨äºåç»­åŒ¹é…ï¼‰
        upload_start_time = datetime.utcnow()

        with open(file_path, 'rb') as f:
            files = {'file': (filename, f, 'text/markdown')}
            data = {
                'background': background,
                'auto_process': str(auto_process).lower()
            }

            response = requests.post(url, files=files, data=data)
            response.raise_for_status()

        result = response.json()

        # æ‰“å°å®Œæ•´çš„ API å“åº”ï¼ˆæ–¹ä¾¿è°ƒè¯•ï¼‰
        print(f"\nğŸ“‹ API ä¸Šä¼ å“åº”:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
        print()

        # æ£€æŸ¥ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        if not result.get('success'):
            error_msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
            raise Exception(f"ä¸Šä¼ å¤±è´¥: {error_msg}")

        print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ")

        # ğŸ¯ æ–¹æ¡ˆ 1ï¼šå°è¯•ä»å“åº”ä¸­ç›´æ¥è·å– article_id
        data_obj = result.get('data', {})
        article_id_from_response = data_obj.get('article_id')

        if article_id_from_response and str(article_id_from_response) != 'null':
            print(f"âœ… ä»å“åº”è·å–åˆ° article_id: {article_id_from_response}")
            return {
                'article_id': article_id_from_response,
                'filename': filename,
                'source_config_id': source_config_id,
                'method': 'response'
            }

        # ğŸ¯ æ–¹æ¡ˆ 2ï¼šå“åº”ä¸­æ²¡æœ‰ article_idï¼Œé€šè¿‡æ–‡æ¡£åˆ—è¡¨æŸ¥è¯¢ï¼ˆæ¨¡ä»¿ Web ç«¯é€»è¾‘ï¼‰
        print(f"âš ï¸  å“åº”ä¸­ article_id ä¸º nullï¼Œä½¿ç”¨åˆ—è¡¨æŸ¥è¯¢...")

        article_id = self._find_document_from_list(
            source_config_id=source_config_id,
            filename=filename,
            upload_time=upload_start_time,
            max_attempts=10,
            interval=2
        )

        print(f"âœ… è·å–åˆ° Article ID: {article_id}\n")

        # è¿”å›åŒ…å« article_id çš„æ•°æ®
        return {
            'article_id': article_id,
            'filename': filename,
            'source_config_id': source_config_id,
            'method': 'list_query'
        }

    def wait_for_completion(
        self,
        article_id: str,
        max_attempts: int = 60,
        poll_interval: int = 2
    ) -> Dict[str, Any]:
        """
        ç­‰å¾…æ–‡æ¡£å¤„ç†å®Œæˆï¼ˆè½®è¯¢çŠ¶æ€ï¼‰

        Args:
            article_id: æ–‡æ¡£ ID
            max_attempts: æœ€å¤§å°è¯•æ¬¡æ•°
            poll_interval: è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰

        Returns:
            æ–‡æ¡£æœ€ç»ˆçŠ¶æ€
        """
        # éªŒè¯ article_id
        if not article_id or str(article_id).lower() in ['none', 'null', '']:
            raise ValueError(f"âŒ æ— æ•ˆçš„ article_id: {article_id}")

        url = f"{self.api_base_url}/documents/{article_id}"

        print(f"â³ ç­‰å¾…äº‹é¡¹ç”Ÿæˆå®Œæˆ... (article_id: {article_id})")

        for attempt in range(1, max_attempts + 1):
            response = requests.get(url)
            response.raise_for_status()

            result = response.json()
            data = result['data']
            status = data['status']
            events_count = data.get('events_count', 0)

            if status == 'COMPLETED':
                print(f"âœ… äº‹é¡¹ç”Ÿæˆå®Œæˆï¼å…±ç”Ÿæˆ {events_count} ä¸ªäº‹é¡¹\n")
                return data
            elif status == 'FAILED':
                error_msg = data.get('error_message', 'æœªçŸ¥é”™è¯¯')
                raise Exception(f"âŒ äº‹é¡¹ç”Ÿæˆå¤±è´¥: {error_msg}")
            else:
                print(f"   è¿›åº¦: {attempt}/{max_attempts} - çŠ¶æ€: {status}")
                time.sleep(poll_interval)

        raise TimeoutError(f"âŒ è½®è¯¢è¶…æ—¶ï¼šè¶…è¿‡ {max_attempts * poll_interval} ç§’")

    def search_events(
        self,
        source_config_id: str,
        query: str,
        mode: str = "fast",
        top_k: int = 5,
        threshold: float = 0.5
    ) -> List[Dict[str, Any]]:
        """
        æ ¹æ®é—®é¢˜æœç´¢äº‹é¡¹

        Args:
            source_config_id: ä¿¡æ¯æº ID
            query: æŸ¥è¯¢é—®é¢˜
            mode: æœç´¢æ¨¡å¼ï¼ˆfast/normalï¼‰
            top_k: è¿”å›å‰ K ä¸ªç»“æœ
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼

        Returns:
            æœç´¢åˆ°çš„äº‹é¡¹åˆ—è¡¨
        """
        url = f"{self.api_base_url}/pipeline/search"

        payload = {
            "source_config_id": source_config_id,
            "query": query,
            "mode": mode,
            "top_k": top_k,
            "threshold": threshold
        }

        print(f"ğŸ” æœç´¢é—®é¢˜: {query}")
        response = requests.post(url, json=payload)
        response.raise_for_status()

        result = response.json()
        events = result['data'].get('events', [])

        print(f"âœ… æ‰¾åˆ° {len(events)} ä¸ªç›¸å…³äº‹é¡¹\n")

        # # æ‰“å°æœç´¢ç»“æœ
        # for i, event in enumerate(events, 1):
        #     print(f"{i}. {event.get('title', 'N/A')}")
        #     print(f"   summary: {event.get('summary', 'N/A')}")
        #     print(f"   content: {event.get('content', 'N/A')}")

        return events

    def delete_source(self, source_config_id: str):
        """
        åˆ é™¤ä¿¡æ¯æºï¼ˆçº§è”åˆ é™¤æ‰€æœ‰æ•°æ®ï¼‰

        Args:
            source_config_id: ä¿¡æ¯æº ID
        """
        url = f"{self.api_base_url}/sources/{source_config_id}"

        print(f"ğŸ—‘ï¸  åˆ é™¤ä¿¡æ¯æº: {source_config_id}")
        response = requests.delete(url)
        response.raise_for_status()

        print(f"âœ… ä¿¡æ¯æºå·²åˆ é™¤ï¼ˆåŒ…æ‹¬æ‰€æœ‰æ–‡æ¡£å’Œäº‹é¡¹ï¼‰\n")

    def run_pipeline(
        self,
        sample_limit: int = 1,
        config: str = "distractor",
        cleanup: bool = False,
        output_dir: str = "./hotpotqa_output"
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„æµ‹è¯•æµç¨‹

        Args:
            sample_limit: è¦å¤„ç†çš„æ ·æœ¬æ•°é‡
            config: HotpotQA é…ç½®ï¼ˆdistractor/fullwikiï¼‰
            cleanup: æ˜¯å¦åœ¨ç»“æŸåæ¸…ç†æ•°æ®
            output_dir: MD æ–‡ä»¶è¾“å‡ºç›®å½•

        Returns:
            æµç¨‹æ‰§è¡Œç»“æœ
        """
        if not self.loader:
            raise ValueError("æœªè®¾ç½® dataset_pathï¼Œæ— æ³•åŠ è½½æ•°æ®é›†")

        print("="*60)
        print("ğŸš€ HotpotQA æ£€ç´¢ç³»ç»Ÿæµ‹è¯•æµç¨‹")
        print("="*60 + "\n")

        # 1. åŠ è½½æ•°æ®é›†
        print(f"ğŸ“Š åŠ è½½ HotpotQA æ•°æ®é›†...")
        samples = self.loader.load_validation(
            config=config, limit=sample_limit)
        print(f"âœ“ åŠ è½½äº† {len(samples)} ä¸ªæ ·æœ¬\n")

        results = {
            "samples": [],
            "source_config_id": None,
            "total_samples": len(samples)
        }

        # 2. åˆ›å»ºä¿¡æ¯æº
        source_data = self.create_source(
            name=f"HotpotQA æµ‹è¯•é›† ({config})",
            description=f"åŒ…å« {len(samples)} ä¸ª HotpotQA æ ·æœ¬"
        )
        source_config_id = source_data['id']
        results['source_config_id'] = source_config_id

        try:
            # 3. å¤„ç†æ¯ä¸ªæ ·æœ¬
            for i, sample in enumerate(samples, 1):
                print(f"\n{'='*60}")
                print(f"ğŸ“„ å¤„ç†æ ·æœ¬ {i}/{len(samples)}: {sample['id']}")
                print(f"{'='*60}\n")

                sample_result = {
                    "sample_id": sample['id'],
                    "question": sample['question'],
                    "answer": sample['answer'],
                    "type": sample['type'],
                    "level": sample['level']
                }

                # 3.1 è½¬æ¢ä¸º MD æ–‡ä»¶
                md_filename = f"{sample['id']}.md"
                md_path = Path(output_dir) / md_filename
                self.save_sample_to_md(sample, str(md_path))
                sample_result['md_file'] = str(md_path)

                # 3.2 ä¸Šä¼ åˆ°ä¿¡æ¯æº
                upload_result = self.upload_document(
                    source_config_id=source_config_id,
                    file_path=str(md_path),
                    background=f"é—®é¢˜: {sample['question']}"
                )
                sample_result['article_id'] = upload_result['article_id']

                # 3.3 ç­‰å¾…å¤„ç†å®Œæˆ
                doc_status = self.wait_for_completion(
                    article_id=upload_result['article_id']
                )
                sample_result['events_count'] = doc_status.get(
                    'events_count', 0)

                # 3.4 ä½¿ç”¨åŸé—®é¢˜æœç´¢
                search_results = self.search_events(
                    source_config_id=source_config_id,
                    query=sample['question'],
                    top_k=5
                )
                sample_result['search_results'] = search_results

                results['samples'].append(sample_result)

            # 4. æ€»ç»“
            print("\n" + "="*60)
            print("ğŸ“Š æµç¨‹æ‰§è¡Œå®Œæˆ")
            print("="*60)
            print(f"âœ“ å¤„ç†æ ·æœ¬æ•°: {len(results['samples'])}")
            print(f"âœ“ ä¿¡æ¯æº ID: {source_config_id}")

            total_events = sum(s['events_count'] for s in results['samples'])
            print(f"âœ“ ç”Ÿæˆäº‹é¡¹æ€»æ•°: {total_events}")

        finally:
            # 5. æ¸…ç†ï¼ˆå¯é€‰ï¼‰
            if cleanup:
                print("\n")
                self.delete_source(source_config_id)

        return results


def main():
    """ç¤ºä¾‹ç”¨æ³•"""

    # é…ç½®å‚æ•°
    API_BASE_URL = "http://localhost:8000/api/v1"
    DATASET_PATH = r"C:\Users\user\Downloads\bench dataset\datasets--hotpotqa--hotpot_qa\snapshots\1908d6afbbead072334abe2965f91bd2709910ab"

    # åˆ›å»ºç®¡é“
    pipeline = HotpotQAPipeline(
        api_base_url=API_BASE_URL,
        dataset_path=DATASET_PATH
    )

    # è¿è¡Œå®Œæ•´æµç¨‹ï¼ˆå¤„ç† 3 ä¸ªæ ·æœ¬ï¼‰
    results = pipeline.run_pipeline(
        sample_limit=3,
        config="distractor",
        cleanup=False,  # è®¾ç½®ä¸º True ä¼šåœ¨ç»“æŸååˆ é™¤ä¿¡æ¯æº
        output_dir="./hotpotqa_output"
    )

    # ä¿å­˜ç»“æœ
    output_file = Path("./hotpotqa_test_results.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")


if __name__ == "__main__":
    main()
